{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741201963795,
     "user": {
      "displayName": "Onur Cay",
      "userId": "09681506537499586844"
     },
     "user_tz": 0
    },
    "id": "ECtXMOfXYHPt",
    "outputId": "8e9c24ad-9428-41ea-dded-6c096e7914da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower 1.15.2 is installed\n"
     ]
    }
   ],
   "source": [
    "import flwr\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "print(f\"Flower {flwr.__version__} is installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741201963814,
     "user": {
      "displayName": "Onur Cay",
      "userId": "09681506537499586844"
     },
     "user_tz": 0
    },
    "id": "9gpdgjhGuulp"
   },
   "outputs": [],
   "source": [
    "def load_federated_data(num_clients, alpha, test_size, val_size):\n",
    "    \"\"\"\n",
    "    Loads the CSV file, drops the 'attack_cat' column if present, and converts specified \n",
    "    non-numeric columns (\"proto\", \"service\", \"state\") to numeric using label encoding.\n",
    "    The dataset is then split globally into training, validation, and test sets.\n",
    "    The global training set is partitioned non-iid among clients using Flower's DirichletPartitioner.\n",
    "    \n",
    "    Args:\n",
    "        num_clients (int): Number of federated clients.\n",
    "        alpha (float): Dirichlet concentration parameter.\n",
    "        test_size (float): Fraction of the overall data to reserve as test data.\n",
    "        val_size (float): Fraction of the overall data to reserve as validation data.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - dict: A dictionary mapping client IDs to their local training DataFrame.\n",
    "            - pd.DataFrame: The global test set.\n",
    "            - pd.DataFrame: The global validation set.\n",
    "            - dict: A dictionary mapping each of the categorical columns (\"proto\", \"service\", \"state\")\n",
    "                    to its label encoder mapping (list of classes).\n",
    "    \"\"\"\n",
    "    # Hard-coded file path and random seed\n",
    "    file_path = \"./Datasets/merged_UNSW_NB15.csv\"\n",
    "    random_state = 42\n",
    "\n",
    "    # Load CSV into a pandas DataFrame and drop the 'attack_cat' column if it exists\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Original data shape:\", df.shape)\n",
    "    if \"attack_cat\" in df.columns:\n",
    "        df.drop(columns=[\"attack_cat\"], inplace=True)\n",
    "        print(\"Dropped 'attack_cat'. New shape:\", df.shape)\n",
    "\n",
    "    \n",
    "    # Label encoding for specified categorical columns\n",
    "    label_encoders = {}\n",
    "    for col in [\"proto\", \"service\", \"state\"]:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            label_encoders[col] = {\"classes\": le.classes_.tolist()}\n",
    "            print(f\"Column '{col}' encoded with classes: {le.classes_.tolist()}\")\n",
    "    \n",
    "    # Global split: first separate out the combined test+validation set.\n",
    "    total_test_val = test_size + val_size\n",
    "    print(total_test_val)\n",
    "    global_train, global_test_val = train_test_split(\n",
    "        df,\n",
    "        test_size=total_test_val,\n",
    "        stratify=df[\"label\"],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Split the global test+validation set into separate test and validation sets.\n",
    "    if val_size == 0:\n",
    "        print(\"No Val size set doing centralised training\")\n",
    "    elif test_size == 0:\n",
    "        print(\"No Test size please set a test size\")\n",
    "        return\n",
    "    else:\n",
    "        test_ratio = test_size / total_test_val\n",
    "        global_test, global_val = train_test_split(\n",
    "            global_test_val,\n",
    "            test_size=(1 - test_ratio),\n",
    "            stratify=global_test_val[\"label\"],\n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "    print(\"Global train shape:\", global_train.shape)\n",
    "    print(\"Global validation shape:\", global_val.shape) if val_size != 0 else print(\"No validation set\")\n",
    "    print(\"Global test shape:\", global_test.shape) if val_size != 0 else print(\"Global test shape:\", global_test_val.shape)\n",
    "    \n",
    "    # Partition the global training data among clients using Flower's DirichletPartitioner.\n",
    "    if num_clients == 1:\n",
    "        # If there is only one client, return the entire training set as the client's training set.\n",
    "        return {0: global_train}, global_test_val, global_test_val, label_encoders #Val is not needed for centralised\n",
    "    hf_train_dataset = Dataset.from_pandas(global_train,preserve_index=False)\n",
    "    partitioner = DirichletPartitioner(\n",
    "        num_partitions=num_clients,\n",
    "        partition_by=\"label\",\n",
    "        alpha=alpha,\n",
    "        min_partition_size=10,\n",
    "        self_balancing=True,\n",
    "        shuffle=True,\n",
    "        seed=random_state,\n",
    "    )\n",
    "    partitioner.dataset = hf_train_dataset\n",
    "    \n",
    "    client_train_dataset = {}\n",
    "    \n",
    "    \n",
    "    # For each client, load the iid training partition.\n",
    "    for client in range(num_clients):\n",
    "        client_train = partitioner.load_partition(client).to_pandas()\n",
    "        client_train_dataset[client] = client_train\n",
    "        print(f\"Client {client}: Train {client_train.shape}\")\n",
    "    \n",
    "    return client_train_dataset, global_test, global_val, label_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsTracker:\n",
    "    def __init__(self, output_dir=\"metrics\"):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.metrics = []\n",
    "\n",
    "    def log_round_metrics(self, round_num, global_metrics, client_metrics, merge_method, num_clients, num_trees, max_depth, criterion):\n",
    "        round_metrics = {\n",
    "            \"round_num\": round_num,\n",
    "            \"merge_method\": merge_method,\n",
    "            \"num_clients\": num_clients,\n",
    "            \"num_trees\": num_trees,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"criterion\": criterion,\n",
    "        }\n",
    "        round_metrics.update(global_metrics)\n",
    "        round_metrics.update(client_metrics)\n",
    "        self.metrics.append(round_metrics)\n",
    "\n",
    "    def save_metrics_to_csv(self, filename=\"metrics.csv\"):\n",
    "        keys = self.metrics[0].keys()\n",
    "        with open(os.path.join(self.output_dir, filename), 'w', newline='') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(self.metrics)\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        rounds = [m[\"round_num\"] for m in self.metrics]\n",
    "        accuracies = [m[\"global_accuracy\"] for m in self.metrics]\n",
    "        recalls = [m[\"global_recall\"] for m in self.metrics]\n",
    "        roc_aucs = [m[\"global_roc_auc\"] for m in self.metrics]\n",
    "        precisions = [m[\"global_precision\"] for m in self.metrics]\n",
    "        f1_scores = [m[\"global_f1_score\"] for m in self.metrics]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(rounds, accuracies, label=\"Accuracy\")\n",
    "        plt.plot(rounds, recalls, label=\"Recall\")\n",
    "        plt.plot(rounds, roc_aucs, label=\"ROC AUC\")\n",
    "        plt.plot(rounds, precisions, label=\"Precision\")\n",
    "        plt.plot(rounds, f1_scores, label=\"F1 Score\")\n",
    "        plt.xlabel(\"Round\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Global Model Metrics Over Rounds\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(self.output_dir, \"metrics_plot.png\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMerger:\n",
    "    def __init__(self, global_val):\n",
    "        \"\"\"\n",
    "        Initialize with the global validation dataset.\n",
    "        This dataset is used for methods that need to evaluate model performance.\n",
    "        \"\"\"\n",
    "        self.global_val = global_val\n",
    "\n",
    "    def merge_models_randomly(self, client_models, num_input):\n",
    "        # Collect all trees from all client models.\n",
    "        all_trees = [tree for model in client_models for tree in model.estimators_]\n",
    "        print(\"Number of trees in global model:\", len(all_trees))\n",
    "        selected_trees = random.sample(all_trees, min(len(all_trees), num_input))\n",
    "        \n",
    "        merged_model = RandomForestClassifier(n_estimators=0, warm_start=True)\n",
    "        source_model = client_models[0]\n",
    "        \n",
    "        merged_model.n_features_in_ = source_model.n_features_in_\n",
    "        merged_model.classes_ = source_model.classes_\n",
    "        merged_model.n_classes_ = len(source_model.classes_)\n",
    "        merged_model.n_outputs_ = 1\n",
    "        if hasattr(source_model, 'feature_names_in_'):\n",
    "            merged_model.feature_names_in_ = source_model.feature_names_in_\n",
    "            \n",
    "        merged_model.estimators_ = selected_trees\n",
    "        merged_model.n_estimators = len(selected_trees)\n",
    "        return merged_model\n",
    "\n",
    "    def merge_models_by_impurity(self, client_models, num_input):\n",
    "        all_trees = []\n",
    "        # Collect all trees along with their root node impurity (lower is better)\n",
    "        for model in client_models:\n",
    "            for tree in model.estimators_:\n",
    "                root_impurity = tree.tree_.impurity[0]\n",
    "                all_trees.append((tree, root_impurity))\n",
    "                \n",
    "        sorted_trees = sorted(all_trees, key=lambda x: x[1])\n",
    "        selected_trees = [tree for tree, _ in sorted_trees[:num_input]]\n",
    "        print(\"Number of trees selected for global model:\", len(selected_trees))\n",
    "        \n",
    "        merged_model = RandomForestClassifier(n_estimators=0, warm_start=True)\n",
    "        source_model = client_models[0]\n",
    "        merged_model.n_features_in_ = source_model.n_features_in_\n",
    "        merged_model.classes_ = source_model.classes_\n",
    "        merged_model.n_classes_ = len(source_model.classes_)\n",
    "        merged_model.n_outputs_ = 1\n",
    "        if hasattr(source_model, \"feature_names_in_\"):\n",
    "            merged_model.feature_names_in_ = source_model.feature_names_in_\n",
    "            \n",
    "        merged_model.estimators_ = selected_trees\n",
    "        merged_model.n_estimators = len(selected_trees)\n",
    "        return merged_model\n",
    "\n",
    "    def merge_models_weight_global(self, client_models, num_input):\n",
    "        X_val = self.global_val.drop(columns=[\"label\"]).values\n",
    "        y_val = self.global_val[\"label\"].values\n",
    "        all_trees = [(tree, accuracy_score(tree.predict(X_val), y_val))\n",
    "                     for model in client_models for tree in model.estimators_]\n",
    "        best_trees = sorted(all_trees, key=lambda x: x[1], reverse=True)[:num_input]\n",
    "        merged_model = RandomForestClassifier(n_estimators=len(best_trees), warm_start=True)\n",
    "        merged_model.estimators_ = [tree for tree, _ in best_trees]\n",
    "        return merged_model\n",
    "\n",
    "    def merge_models_diversity(self, client_models, num_input):\n",
    "        \"\"\"\n",
    "        Select trees to maximize feature diversity in the global model.\n",
    "        \"\"\"\n",
    "        all_trees = [tree for model in client_models for tree in model.estimators_]\n",
    "        # First, select a few of the best trees based on impurity.\n",
    "        tree_impurities = [(tree, tree.tree_.impurity[0]) for tree in all_trees]\n",
    "        sorted_trees = sorted(tree_impurities, key=lambda x: x[1])\n",
    "        selected_trees = [tree for tree, _ in sorted_trees[:num_input // 4]]\n",
    "        \n",
    "        remaining_trees = [tree for tree, _ in sorted_trees[num_input // 4:]]\n",
    "        feature_usage = {}\n",
    "        # Initialize feature usage from already selected trees.\n",
    "        for tree in selected_trees:\n",
    "            for feature in self._get_important_features(tree):\n",
    "                feature_usage[feature] = feature_usage.get(feature, 0) + 1\n",
    "        \n",
    "        # Greedy selection to maximize feature diversity.\n",
    "        while len(selected_trees) < num_input and remaining_trees:\n",
    "            best_tree = None\n",
    "            best_score = None\n",
    "            best_tree_idx = None\n",
    "            for idx, tree in enumerate(remaining_trees):\n",
    "                tree_features = self._get_important_features(tree)\n",
    "                if not tree_features:\n",
    "                    continue\n",
    "                score = sum(feature_usage.get(feature, 0) for feature in tree_features) / len(tree_features)\n",
    "                if best_tree is None or score < best_score:\n",
    "                    best_tree = tree\n",
    "                    best_score = score\n",
    "                    best_tree_idx = idx\n",
    "            if best_tree is None:\n",
    "                break\n",
    "            selected_trees.append(best_tree)\n",
    "            remaining_trees.pop(best_tree_idx)\n",
    "            for feature in self._get_important_features(best_tree):\n",
    "                feature_usage[feature] = feature_usage.get(feature, 0) + 1\n",
    "        \n",
    "        merged_model = RandomForestClassifier(n_estimators=0, warm_start=True)\n",
    "        source_model = client_models[0]\n",
    "        merged_model.n_features_in_ = source_model.n_features_in_\n",
    "        merged_model.classes_ = source_model.classes_\n",
    "        merged_model.n_classes_ = len(source_model.classes_)\n",
    "        merged_model.n_outputs_ = 1\n",
    "        if hasattr(source_model, 'feature_names_in_'):\n",
    "            merged_model.feature_names_in_ = source_model.feature_names_in_\n",
    "        merged_model.estimators_ = selected_trees\n",
    "        merged_model.n_estimators = len(selected_trees)\n",
    "        return merged_model\n",
    "\n",
    "    def merge_models_weighted_voting(self, client_models, num_input):\n",
    "        \"\"\"\n",
    "        Create an ensemble where each client contributes proportionally to their local performance.\n",
    "        \"\"\"\n",
    "        client_scores = []\n",
    "        # Use global_val as the evaluation set.\n",
    "        X_val = self.global_val.drop(columns=[\"label\"]).values\n",
    "        y_val = self.global_val[\"label\"].values\n",
    "        for i, model in enumerate(client_models):\n",
    "            score = accuracy_score(model.predict(X_val), y_val)\n",
    "            client_scores.append((i, score))\n",
    "        \n",
    "        sorted_clients = sorted(client_scores, key=lambda x: x[1], reverse=True)\n",
    "        total_score = sum(score for _, score in sorted_clients)\n",
    "        trees_per_client = {}\n",
    "        remaining_trees = num_input\n",
    "        for idx, (client_idx, score) in enumerate(sorted_clients):\n",
    "            if idx == len(sorted_clients) - 1:\n",
    "                trees_per_client[client_idx] = remaining_trees\n",
    "            else:\n",
    "                client_trees = max(1, int((score / total_score) * num_input))\n",
    "                trees_per_client[client_idx] = min(client_trees, remaining_trees)\n",
    "                remaining_trees -= trees_per_client[client_idx]\n",
    "        \n",
    "        selected_trees = []\n",
    "        for i, model in enumerate(client_models):\n",
    "            if i not in trees_per_client or trees_per_client[i] == 0:\n",
    "                continue\n",
    "            trees_to_select = trees_per_client[i]\n",
    "            if trees_to_select >= len(model.estimators_):\n",
    "                selected_trees.extend(model.estimators_)\n",
    "            else:\n",
    "                tree_impurities = [(tree, tree.tree_.impurity[0]) for tree in model.estimators_]\n",
    "                sorted_trees = sorted(tree_impurities, key=lambda x: x[1])\n",
    "                selected_trees.extend([tree for tree, _ in sorted_trees[:trees_to_select]])\n",
    "        \n",
    "        merged_model = RandomForestClassifier(n_estimators=0, warm_start=True)\n",
    "        source_model = client_models[0]\n",
    "        merged_model.n_features_in_ = source_model.n_features_in_\n",
    "        merged_model.classes_ = source_model.classes_\n",
    "        merged_model.n_classes_ = len(source_model.classes_)\n",
    "        merged_model.n_outputs_ = 1\n",
    "        if hasattr(source_model, 'feature_names_in_'):\n",
    "            merged_model.feature_names_in_ = source_model.feature_names_in_\n",
    "        merged_model.estimators_ = selected_trees\n",
    "        merged_model.n_estimators = len(selected_trees)\n",
    "        return merged_model\n",
    "    \n",
    "    def merge_models_prune_similar(self, client_models):\n",
    "        print(\"Number of trees in global model before prune:\", sum(len(model.estimators_) for model in client_models))\n",
    "        unique_trees = []\n",
    "        pruned_client_models = []\n",
    "        for model in client_models:\n",
    "            pruned_estimators = []\n",
    "            for tree in model.estimators_:\n",
    "                if not any(self.are_trees_similar(tree, existing_tree) for existing_tree in unique_trees):\n",
    "                    unique_trees.append(tree)\n",
    "                    pruned_estimators.append(tree)\n",
    "            pruned_model = RandomForestClassifier(n_estimators=len(pruned_estimators), warm_start=True)\n",
    "            pruned_model.estimators_ = pruned_estimators\n",
    "            pruned_client_models.append(pruned_model)\n",
    "        print(\"Number of trees in global model after prune:\", len(unique_trees))\n",
    "        return pruned_client_models\n",
    "\n",
    "    def are_trees_similar(self, tree1, tree2, similarity_threshold=0.8):\n",
    "        \"\"\"Compare two trees based on their structure and parameters.\"\"\"\n",
    "        tree1_struct = tree1.tree_\n",
    "        tree2_struct = tree2.tree_\n",
    "        \n",
    "        # If trees have very different node counts, they're not similar\n",
    "        if abs(tree1_struct.node_count - tree2_struct.node_count) > 5:\n",
    "            return False\n",
    "        \n",
    "        # Check only the first few nodes for efficiency.\n",
    "        max_check_node = min(7, min(tree1_struct.node_count, tree2_struct.node_count))\n",
    "        similar_nodes = 0\n",
    "        for i in range(max_check_node):\n",
    "            # If both nodes are leaf nodes, count as similar\n",
    "            if tree1_struct.children_left[i] == -1 and tree2_struct.children_left[i] == -1:\n",
    "                similar_nodes += 1\n",
    "                continue\n",
    "            \n",
    "            # If one is leaf and the other is not, skip comparison.\n",
    "            if (tree1_struct.children_left[i] == -1) != (tree2_struct.children_left[i] == -1):\n",
    "                continue\n",
    "                \n",
    "            # Check if split features are the same and thresholds are close.\n",
    "            if tree1_struct.feature[i] == tree2_struct.feature[i]:\n",
    "                if abs(tree1_struct.threshold[i] - tree2_struct.threshold[i]) < 0.1:\n",
    "                    similar_nodes += 1\n",
    "        \n",
    "        similarity = similar_nodes / max_check_node\n",
    "        return similarity > similarity_threshold\n",
    "    \n",
    "    def _get_important_features(self, tree, importance_threshold=0.01):\n",
    "        \"\"\"Helper function to extract important features from a tree.\"\"\"\n",
    "        importances = tree.feature_importances_\n",
    "        return [i for i, imp in enumerate(importances) if imp > importance_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"Utility class for evaluating models with patched predictions for class imbalance.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def patch_single_tree_proba(p, model_classes, global_classes):\n",
    "        full_p = np.zeros((p.shape[0], len(global_classes)))\n",
    "        for i, cls in enumerate(global_classes):\n",
    "            if cls in model_classes:\n",
    "                full_p[:, i] = p[:, model_classes == cls].flatten()\n",
    "        return full_p\n",
    "    \n",
    "    @staticmethod\n",
    "    def patched_predict_proba(model, X, global_classes):\n",
    "        tree_probas = []\n",
    "        for tree in model.estimators_:\n",
    "            p = tree.predict_proba(X)\n",
    "            tree_model_classes = tree.classes_\n",
    "            patched_p = ModelEvaluator.patch_single_tree_proba(p, tree_model_classes, global_classes)\n",
    "            tree_probas.append(patched_p)\n",
    "        return np.mean(tree_probas, axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate_model(model, X_test, y_test, model_name=\"Model\", global_classes=None):\n",
    "        if global_classes is None:\n",
    "            global_classes = np.sort(np.unique(y_test))\n",
    "            \n",
    "        try:\n",
    "            proba = ModelEvaluator.patched_predict_proba(model, X_test, global_classes)\n",
    "            y_pred = global_classes[np.argmax(proba, axis=1)]\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred, average='macro',zero_division=0)\n",
    "            precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, average='macro',zero_division=0)\n",
    "            \n",
    "            # Ensure y_test is a 1-dimensional array\n",
    "            if y_test.ndim > 1 and y_test.shape[1] > 1:\n",
    "                y_test = np.argmax(y_test, axis=1)\n",
    "            \n",
    "            try:\n",
    "                if len(global_classes) == 2:\n",
    "                    # For binary classification, use the probabilities for the positive class.\n",
    "                    roc_auc = roc_auc_score(y_test, proba[:, 1])\n",
    "                else:\n",
    "                    # For multi-class classification.\n",
    "                    roc_auc = roc_auc_score(y_test, proba, multi_class='ovr')\n",
    "            except ValueError as e:\n",
    "                print(f\"Error calculating ROC AUC for {model_name}: {e}\")\n",
    "                roc_auc = None\n",
    "            \n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"recall\": recall,\n",
    "                \"roc_auc\": float(roc_auc),\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": f1\n",
    "            }\n",
    "            \n",
    "            print(f\"{model_name} accuracy: {metrics.get('accuracy')}\")\n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {model_name}: {e}\")\n",
    "            return {\n",
    "                \"accuracy\": None,\n",
    "                \"recall\": None,\n",
    "                \"roc_auc\": None,\n",
    "                \"precision\": None,\n",
    "                \"f1_score\": None\n",
    "            }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1741201963870,
     "user": {
      "displayName": "Onur Cay",
      "userId": "09681506537499586844"
     },
     "user_tz": 0
    },
    "id": "Me_skoQaO9tj"
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, num_clients, clients_per_round, merge_method, num_global_trees, global_test_data, global_val_data, prune_similar):\n",
    "        self.num_clients = num_clients\n",
    "        self.clients_per_round = clients_per_round\n",
    "        self.merge_method = merge_method\n",
    "        self.num_global_trees = num_global_trees\n",
    "        self.clients = []\n",
    "        self.global_model = RandomForestClassifier(n_estimators=0, warm_start=True)\n",
    "        self.global_test = global_test_data\n",
    "        self.global_val = global_val_data\n",
    "        self.model_merger = ModelMerger(self.global_val)\n",
    "        self.prune_similar = prune_similar\n",
    "        \n",
    "\n",
    "    def register_client(self, client):\n",
    "        self.clients.append(client)\n",
    "\n",
    "    def select_clients(self):\n",
    "      # Randomly choose clients each round\n",
    "      random.seed(42) # For reproducibility\n",
    "      available_clients = random.sample(self.clients, self.clients_per_round)\n",
    "      print(f\"Selected Clients: {[client.client_id for client in available_clients]}\")\n",
    "      return available_clients\n",
    "\n",
    "    def merge_models(self, client_models):\n",
    "        # Map merge method names to the corresponding ModelMerger method.\n",
    "        merge_strategies = {\n",
    "            \"random\": self.model_merger.merge_models_randomly,\n",
    "            \"weight_global\": self.model_merger.merge_models_weight_global,\n",
    "            \"weight_voting\": self.model_merger.merge_models_weighted_voting,\n",
    "            \"impurity\": self.model_merger.merge_models_by_impurity,\n",
    "            \"diversity\": self.model_merger.merge_models_diversity,\n",
    "            \n",
    "        }\n",
    "        if self.merge_method not in merge_strategies:\n",
    "            raise ValueError(f\"Invalid merge method: {self.merge_method}\")\n",
    "        # Some methods (like prune_similar) do not require the num_global_trees parameter.\n",
    "        if self.prune_similar:\n",
    "            pruned_client_models = self.model_merger.merge_models_prune_similar(client_models)\n",
    "            return merge_strategies[self.merge_method](pruned_client_models, self.num_global_trees)\n",
    "        return merge_strategies[self.merge_method](client_models, self.num_global_trees)\n",
    "\n",
    "    def distribute_global_model(self):\n",
    "        for client in self.clients:\n",
    "            client.update_model(self.global_model)\n",
    "        print(\"Global model distributed to all clients.\")\n",
    "    \n",
    "    \n",
    "    def evaluate_global_model(self):\n",
    "        X_test = self.global_test.drop(columns=[\"label\"]).values\n",
    "        y_test = self.global_test[\"label\"].values\n",
    "        return ModelEvaluator.evaluate_model(self.global_model, X_test, y_test, \"Global model\")\n",
    "\n",
    "    def train_federated(self, configs):\n",
    "        for round_num in range(1, configs[\"num_rounds\"] + 1):\n",
    "            print(f\"\\nStarting Round {round_num}\")\n",
    "            selected_clients = self.select_clients()\n",
    "            round_models = []\n",
    "            client_metrics = {}\n",
    "\n",
    "            for client in selected_clients:\n",
    "                client.train(\n",
    "                    configs[\"num_trees\"],\n",
    "                    configs[\"max_depth\"],\n",
    "                    configs[\"num_max_features\"],\n",
    "                    configs[\"n_jobs\"]\n",
    "                )\n",
    "                round_models.append(client.model)\n",
    "\n",
    "            print(\"\\nTraining finished\")\n",
    "            if len(round_models) > 1:\n",
    "                self.global_model = self.merge_models(round_models)\n",
    "            else:\n",
    "                self.global_model = round_models[0]\n",
    "            print(\"\\nMerged models\")\n",
    "            \n",
    "            global_metrics = self.evaluate_global_model()\n",
    "            if global_metrics is None:\n",
    "                global_metrics = {\n",
    "                    \"accuracy\": None,\n",
    "                    \"recall\": None,\n",
    "                    \"roc_auc\": None,\n",
    "                    \"precision\": None,\n",
    "                    \"f1_score\": None\n",
    "                }\n",
    "            metrics_tracker.log_round_metrics(\n",
    "                round_num,\n",
    "                {\"global_\" + k: v for k, v in global_metrics.items()},\n",
    "                client_metrics,\n",
    "                configs[\"merge_method\"],\n",
    "                configs[\"clients_per_round\"],\n",
    "                configs[\"num_trees\"],\n",
    "                configs[\"max_depth\"],\n",
    "                configs[\"criterion\"]\n",
    "            )\n",
    "\n",
    "            print(\"\\nEvaluating Round Results:\")\n",
    "            for client in selected_clients:\n",
    "                client.evaluate()\n",
    "            print(\"Round\",round_num,\"complete!\")\n",
    "            \n",
    "            \n",
    "            self.distribute_global_model()\n",
    "\n",
    "        print(\"\\nFederated Training Complete!\")\n",
    "        metrics_tracker.save_metrics_to_csv()\n",
    "        metrics_tracker.plot_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741201963872,
     "user": {
      "displayName": "Onur Cay",
      "userId": "09681506537499586844"
     },
     "user_tz": 0
    },
    "id": "ssTch5nFAhji"
   },
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, train_data, test_data, model_params):\n",
    "        self.client_id = client_id\n",
    "        self.model_params = model_params\n",
    "        self.model = RandomForestClassifier(**model_params)\n",
    "        # Directly assign preprocessed training and test data\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def train(self, num_trees, max_depth, num_max_features, n_jobs):\n",
    "        print(f\"Trees received from server at Client: {self.client_id} No Estimators: {self.model.n_estimators}\")\n",
    "\n",
    "        X_train = self.train_data.drop(columns=[\"label\"]).values\n",
    "        y_train = self.train_data[\"label\"].values\n",
    "\n",
    "        self.model.n_estimators = num_trees\n",
    "        self.model.max_depth = max_depth\n",
    "        self.model.max_features = num_max_features\n",
    "        self.model.n_jobs = n_jobs\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"Client: {self.client_id} trained {self.model.n_estimators} trees\")\n",
    "\n",
    "        self.prune_redundant_trees() if configs[\"NUM_CLIENTS\"] != 1 or configs[\"client_pruning\"] != True else print(\"No pruning on client\")\n",
    "\n",
    "    def prune_redundant_trees(self):\n",
    "        \"\"\"A simple approach to prune obviously redundant trees.\"\"\"\n",
    "        if self.model.n_estimators <= 5:\n",
    "            return\n",
    "\n",
    "        tree_groups = {}\n",
    "        for i, tree in enumerate(self.model.estimators_):\n",
    "            importances = tree.feature_importances_\n",
    "            top_features = np.argsort(importances)[-3:]\n",
    "            signature = tuple(sorted(top_features))\n",
    "            tree_groups.setdefault(signature, []).append(i)\n",
    "\n",
    "        pruned_trees = []\n",
    "        for group in tree_groups.values():\n",
    "            if len(group) <= 2:\n",
    "                for idx in group:\n",
    "                    pruned_trees.append(self.model.estimators_[idx])\n",
    "            else:\n",
    "                for idx in group[:2]:\n",
    "                    pruned_trees.append(self.model.estimators_[idx])\n",
    "\n",
    "        tree_count_before_prune = self.model.n_estimators\n",
    "        self.model.estimators_ = pruned_trees\n",
    "        self.model.n_estimators = len(pruned_trees)\n",
    "        print(f\"Pruned {tree_count_before_prune - self.model.n_estimators} trees from client {self.client_id}. Total Trees: {self.model.n_estimators}\")\n",
    "\n",
    "    def evaluate(self, global_classes=None):\n",
    "        X_test = self.test_data.drop(columns=[\"label\"]).values\n",
    "        y_test = self.test_data[\"label\"].values\n",
    "        model_name = f\"Client {self.client_id}\"\n",
    "        return ModelEvaluator.evaluate_model(self.model, X_test, y_test, model_name, global_classes)\n",
    "\n",
    "\n",
    "    def update_model(self, global_model):\n",
    "        self.model = copy.deepcopy(global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707,
     "referenced_widgets": [
      "236f61f845c74fc584ee1047f739094c",
      "c605c8b8ef96463aa00f8e4367fee2db",
      "3d5a46c2c6cb46b8801ca26b0fa19ca7",
      "88c4b7ce3de84950a7a58a765ea34f3b",
      "7832e63390ba47d6b747c569ca44d485",
      "da13000f510c4b289ef4988a2f0f03ae",
      "f299f4c6b7f94becba1604779ea76196",
      "1b0b68608a2244edb9681a10af7063b4",
      "538be84d21884997b5a67411ebc84434",
      "a491f1d6c1944e688cb55fab0c27ce91",
      "35759d22a66e4d86bf222f9c512fb26d",
      "ac58bc9084744bbb95e9f8a6d225f66c",
      "93eeff87e78147c38b9ac1286debd53b",
      "25537b892b1d4202bc1708c2c220d20a",
      "a5f0a493bc114963ac372efe419af80c",
      "6e728d14df204639a53627d863dc992f",
      "a1d5833c759c406db33696415842e532",
      "bb9d0339257f479682a36daaa8fe1c84",
      "259af56bcf404b9f979be892612ce575",
      "fc563b13aa0a43adaa00fa00b27f53c0",
      "776d311d33bb492f8f6766cc2796b44f",
      "d170008ddd8049b1bbb095579ab72ee8",
      "051643c631914823943d26107ebfbfe1",
      "07f3f85160624a79a201b0b74f7a12ef",
      "0a93e69a9c8a4043bc6b2734e62a26f8",
      "25bfe18481704dcb88e542208fb4d611",
      "7e06ff0338164874a7ada4759649640c",
      "4aa19145ed694cbeaf2e74217dcdb6d1",
      "abf26fc0ec744b249d63f32a6ee17b46",
      "5dab394178e645af8fc20d80692e39be",
      "4e7a950fb99d4af287a01100ae972c32",
      "0676fbda5810459781d3bfcc05a1b3a1",
      "77dcd4929e424ff6a08b6a5e36a455d1",
      "fe2913e5edd04126b8acda473261a37b",
      "0eb7d12293fe4795a223b86f709f41e0",
      "43e6f98d4d864753b7e5edb68b759722",
      "ce256d87f7d14c84b6796507b9a94c85",
      "380ae28d07b84eeeb40eaec04e110ce6",
      "01dbbc6827d14c868adaca883a806d3d",
      "44c06f599fee445a8d52877df1f74e1f",
      "8a2ec98eb4b64dd4b0c889e1b9ecf5a1",
      "c55be10eeb6c4bbf94d8c84c7af6fa66",
      "f3bfb768d8c147fc94a501742455f84b",
      "1ec1acde58d74c31bd27c05c1a05dc00",
      "a251b19360a64041b1d0222165845246",
      "8c75ae5c8ee648b593c6e784d923c95f",
      "73ec19ee745b4bb89a29942595ba51e6",
      "371a5ea3867c40f4b09f29d885840858",
      "e6566d36061548599aa7f742f5c640e6",
      "e58a06edaae54dbc88879347bd99b0e0",
      "adfd95ebaa964a709cfbce42891c68c1",
      "9bcfe2703c874c218f699e78e436f618",
      "eff344cf223946a89f0ca7e1e929a97f",
      "d915e805716644918d53d9e7194c23d1",
      "027f732d3ff44cab9435cf393c970126",
      "eb4a4f9b49d44884b15de653563c48e4",
      "be19d56b5324423d9506c2bf9b8fd733",
      "0cdc971c598d42fd9a46a0303357ceac",
      "2524b3c9c7da4f3fafcdbc9f39226b75",
      "0993a3dc159e4d318610a7b89e092e65",
      "8cf4285da9104612895b4cf1378e87a0",
      "4a7d6c0afbff4daba41492fc5202d8ac",
      "4dc453d3206149ba8b32f66ab74bbc03",
      "a4bc1347503940f09e79bcfedd38ba2c",
      "7dd5e03466794d5a84a0e7dc776af541",
      "69d321e4bcda4d11811a5406d33806d8"
     ]
    },
    "executionInfo": {
     "elapsed": 26516,
     "status": "error",
     "timestamp": 1741201990416,
     "user": {
      "displayName": "Onur Cay",
      "userId": "09681506537499586844"
     },
     "user_tz": 0
    },
    "id": "n_6sdyagqePT",
    "outputId": "7089cbb0-42c0-4ad8-dc02-fbca76d5846b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (257672, 45)\n",
      "Dropped 'attack_cat'. New shape: (257672, 44)\n",
      "Column 'proto' encoded with classes: ['3pc', 'a/n', 'aes-sp3-d', 'any', 'argus', 'aris', 'arp', 'ax.25', 'bbn-rcc', 'bna', 'br-sat-mon', 'cbt', 'cftp', 'chaos', 'compaq-peer', 'cphb', 'cpnx', 'crtp', 'crudp', 'dcn', 'ddp', 'ddx', 'dgp', 'egp', 'eigrp', 'emcon', 'encap', 'etherip', 'fc', 'fire', 'ggp', 'gmtp', 'gre', 'hmp', 'i-nlsp', 'iatp', 'ib', 'icmp', 'idpr', 'idpr-cmtp', 'idrp', 'ifmp', 'igmp', 'igp', 'il', 'ip', 'ipcomp', 'ipcv', 'ipip', 'iplt', 'ipnip', 'ippc', 'ipv6', 'ipv6-frag', 'ipv6-no', 'ipv6-opts', 'ipv6-route', 'ipx-n-ip', 'irtp', 'isis', 'iso-ip', 'iso-tp4', 'kryptolan', 'l2tp', 'larp', 'leaf-1', 'leaf-2', 'merit-inp', 'mfe-nsp', 'mhrp', 'micp', 'mobile', 'mtp', 'mux', 'narp', 'netblt', 'nsfnet-igp', 'nvp', 'ospf', 'pgm', 'pim', 'pipe', 'pnni', 'pri-enc', 'prm', 'ptp', 'pup', 'pvp', 'qnx', 'rdp', 'rsvp', 'rtp', 'rvd', 'sat-expak', 'sat-mon', 'sccopmce', 'scps', 'sctp', 'sdrp', 'secure-vmtp', 'sep', 'skip', 'sm', 'smp', 'snp', 'sprite-rpc', 'sps', 'srp', 'st2', 'stp', 'sun-nd', 'swipe', 'tcf', 'tcp', 'tlsp', 'tp++', 'trunk-1', 'trunk-2', 'ttp', 'udp', 'unas', 'uti', 'vines', 'visa', 'vmtp', 'vrrp', 'wb-expak', 'wb-mon', 'wsn', 'xnet', 'xns-idp', 'xtp', 'zero']\n",
      "Column 'service' encoded with classes: ['-', 'dhcp', 'dns', 'ftp', 'ftp-data', 'http', 'irc', 'pop3', 'radius', 'smtp', 'snmp', 'ssh', 'ssl']\n",
      "Column 'state' encoded with classes: ['ACC', 'CLO', 'CON', 'ECO', 'FIN', 'INT', 'PAR', 'REQ', 'RST', 'URN', 'no']\n",
      "0.30000000000000004\n",
      "Global train shape: (180370, 44)\n",
      "Global validation shape: (25768, 44)\n",
      "Global test shape: (51534, 44)\n",
      "Client 0: Train (2112, 44)\n",
      "Client 1: Train (2961, 44)\n",
      "Client 2: Train (1047, 44)\n",
      "Client 3: Train (2017, 44)\n",
      "Client 4: Train (1161, 44)\n",
      "Client 5: Train (594, 44)\n",
      "Client 6: Train (3910, 44)\n",
      "Client 7: Train (911, 44)\n",
      "Client 8: Train (1870, 44)\n",
      "Client 9: Train (2597, 44)\n",
      "Client 10: Train (1995, 44)\n",
      "Client 11: Train (6146, 44)\n",
      "Client 12: Train (2148, 44)\n",
      "Client 13: Train (3393, 44)\n",
      "Client 14: Train (608, 44)\n",
      "Client 15: Train (1903, 44)\n",
      "Client 16: Train (1998, 44)\n",
      "Client 17: Train (912, 44)\n",
      "Client 18: Train (845, 44)\n",
      "Client 19: Train (971, 44)\n",
      "Client 20: Train (981, 44)\n",
      "Client 21: Train (2467, 44)\n",
      "Client 22: Train (2645, 44)\n",
      "Client 23: Train (718, 44)\n",
      "Client 24: Train (3029, 44)\n",
      "Client 25: Train (2216, 44)\n",
      "Client 26: Train (1750, 44)\n",
      "Client 27: Train (961, 44)\n",
      "Client 28: Train (2595, 44)\n",
      "Client 29: Train (1679, 44)\n",
      "Client 30: Train (1109, 44)\n",
      "Client 31: Train (1994, 44)\n",
      "Client 32: Train (1361, 44)\n",
      "Client 33: Train (530, 44)\n",
      "Client 34: Train (1964, 44)\n",
      "Client 35: Train (2893, 44)\n",
      "Client 36: Train (226, 44)\n",
      "Client 37: Train (681, 44)\n",
      "Client 38: Train (1072, 44)\n",
      "Client 39: Train (1471, 44)\n",
      "Client 40: Train (2459, 44)\n",
      "Client 41: Train (2221, 44)\n",
      "Client 42: Train (3170, 44)\n",
      "Client 43: Train (978, 44)\n",
      "Client 44: Train (239, 44)\n",
      "Client 45: Train (1216, 44)\n",
      "Client 46: Train (822, 44)\n",
      "Client 47: Train (1298, 44)\n",
      "Client 48: Train (200, 44)\n",
      "Client 49: Train (3796, 44)\n",
      "Client 50: Train (628, 44)\n",
      "Client 51: Train (2151, 44)\n",
      "Client 52: Train (1631, 44)\n",
      "Client 53: Train (3072, 44)\n",
      "Client 54: Train (1183, 44)\n",
      "Client 55: Train (956, 44)\n",
      "Client 56: Train (1027, 44)\n",
      "Client 57: Train (1998, 44)\n",
      "Client 58: Train (869, 44)\n",
      "Client 59: Train (1246, 44)\n",
      "Client 60: Train (812, 44)\n",
      "Client 61: Train (1101, 44)\n",
      "Client 62: Train (3691, 44)\n",
      "Client 63: Train (786, 44)\n",
      "Client 64: Train (1554, 44)\n",
      "Client 65: Train (1279, 44)\n",
      "Client 66: Train (1188, 44)\n",
      "Client 67: Train (5407, 44)\n",
      "Client 68: Train (2182, 44)\n",
      "Client 69: Train (1339, 44)\n",
      "Client 70: Train (4567, 44)\n",
      "Client 71: Train (1461, 44)\n",
      "Client 72: Train (509, 44)\n",
      "Client 73: Train (2582, 44)\n",
      "Client 74: Train (516, 44)\n",
      "Client 75: Train (993, 44)\n",
      "Client 76: Train (2503, 44)\n",
      "Client 77: Train (1987, 44)\n",
      "Client 78: Train (346, 44)\n",
      "Client 79: Train (357, 44)\n",
      "Client 80: Train (1408, 44)\n",
      "Client 81: Train (2619, 44)\n",
      "Client 82: Train (3121, 44)\n",
      "Client 83: Train (830, 44)\n",
      "Client 84: Train (5042, 44)\n",
      "Client 85: Train (3215, 44)\n",
      "Client 86: Train (2378, 44)\n",
      "Client 87: Train (3451, 44)\n",
      "Client 88: Train (1825, 44)\n",
      "Client 89: Train (2098, 44)\n",
      "Client 90: Train (745, 44)\n",
      "Client 91: Train (1917, 44)\n",
      "Client 92: Train (4534, 44)\n",
      "Client 93: Train (185, 44)\n",
      "Client 94: Train (988, 44)\n",
      "Client 95: Train (1338, 44)\n",
      "Client 96: Train (1499, 44)\n",
      "Client 97: Train (2140, 44)\n",
      "Client 98: Train (861, 44)\n",
      "Client 99: Train (1415, 44)\n",
      "Time Elapsed running load data: 5.850822194000102\n",
      "\n",
      "Starting Round 1\n",
      "Selected Clients: [81, 14, 3, 94, 35, 31, 28, 17, 13, 86]\n",
      "Trees received from server at Client: 81 No Estimators: 0\n",
      "Client: 81 trained 200 trees\n",
      "Pruned 198 trees from client 81. Total Trees: 2\n",
      "Estimatorssssssssssssssssssssss 2\n",
      "Trees received from server at Client: 14 No Estimators: 0\n",
      "Client: 14 trained 200 trees\n",
      "Pruned 46 trees from client 14. Total Trees: 154\n",
      "Estimatorssssssssssssssssssssss 154\n",
      "Trees received from server at Client: 3 No Estimators: 0\n",
      "Client: 3 trained 200 trees\n",
      "Pruned 198 trees from client 3. Total Trees: 2\n",
      "Estimatorssssssssssssssssssssss 2\n",
      "Trees received from server at Client: 94 No Estimators: 0\n",
      "Client: 94 trained 200 trees\n",
      "Pruned 95 trees from client 94. Total Trees: 105\n",
      "Estimatorssssssssssssssssssssss 105\n",
      "Trees received from server at Client: 35 No Estimators: 0\n",
      "Client: 35 trained 200 trees\n",
      "Pruned 198 trees from client 35. Total Trees: 2\n",
      "Estimatorssssssssssssssssssssss 2\n",
      "Trees received from server at Client: 31 No Estimators: 0\n",
      "Client: 31 trained 200 trees\n",
      "Pruned 55 trees from client 31. Total Trees: 145\n",
      "Estimatorssssssssssssssssssssss 145\n",
      "Trees received from server at Client: 28 No Estimators: 0\n",
      "Client: 28 trained 200 trees\n",
      "Pruned 114 trees from client 28. Total Trees: 86\n",
      "Estimatorssssssssssssssssssssss 86\n",
      "Trees received from server at Client: 17 No Estimators: 0\n",
      "Client: 17 trained 200 trees\n",
      "Pruned 48 trees from client 17. Total Trees: 152\n",
      "Estimatorssssssssssssssssssssss 152\n",
      "Trees received from server at Client: 13 No Estimators: 0\n",
      "Client: 13 trained 200 trees\n",
      "Pruned 94 trees from client 13. Total Trees: 106\n",
      "Estimatorssssssssssssssssssssss 106\n",
      "Trees received from server at Client: 86 No Estimators: 0\n",
      "Client: 86 trained 200 trees\n",
      "Pruned 77 trees from client 86. Total Trees: 123\n",
      "Estimatorssssssssssssssssssssss 123\n",
      "\n",
      "Training finished\n",
      "\n",
      "Merged models\n",
      "Estimators 100\n",
      "Model size: 214265 bytes\n",
      "Global model accuracy: 0.9275041720029495\n",
      "\n",
      "Evaluating Round Results:\n",
      "Estimators 2\n",
      "Model size: 2369 bytes\n",
      "Client 81 accuracy: 0.36092676679473745\n",
      "Estimators 154\n",
      "Model size: 312009 bytes\n",
      "Client 14 accuracy: 0.852524546901075\n",
      "Estimators 2\n",
      "Model size: 2369 bytes\n",
      "Client 3 accuracy: 0.36092676679473745\n",
      "Estimators 105\n",
      "Model size: 204969 bytes\n",
      "Client 94 accuracy: 0.8279000271665309\n",
      "Estimators 2\n",
      "Model size: 2369 bytes\n",
      "Client 35 accuracy: 0.36092676679473745\n",
      "Estimators 145\n",
      "Model size: 303849 bytes\n",
      "Client 31 accuracy: 0.9145806651919122\n",
      "Estimators 86\n",
      "Model size: 134569 bytes\n",
      "Client 28 accuracy: 0.7143439282803586\n",
      "Estimators 152\n",
      "Model size: 247209 bytes\n",
      "Client 17 accuracy: 0.88822913028292\n",
      "Estimators 106\n",
      "Model size: 231209 bytes\n",
      "Client 13 accuracy: 0.8903636434198782\n",
      "Estimators 123\n",
      "Model size: 281609 bytes\n",
      "Client 86 accuracy: 0.892575775216362\n",
      "Round 1 complete!\n",
      "Global model distributed to all clients.\n",
      "\n",
      "Starting Round 2\n",
      "Selected Clients: [81, 14, 3, 94, 35, 31, 28, 17, 13, 86]\n",
      "Trees received from server at Client: 81 No Estimators: 100\n",
      "Client: 81 trained 200 trees\n",
      "Pruned 99 trees from client 81. Total Trees: 101\n",
      "Estimatorssssssssssssssssssssss 101\n",
      "Trees received from server at Client: 14 No Estimators: 100\n",
      "Client: 14 trained 200 trees\n",
      "Pruned 28 trees from client 14. Total Trees: 172\n",
      "Estimatorssssssssssssssssssssss 172\n",
      "Trees received from server at Client: 3 No Estimators: 100\n",
      "Client: 3 trained 200 trees\n",
      "Pruned 99 trees from client 3. Total Trees: 101\n",
      "Estimatorssssssssssssssssssssss 101\n",
      "Trees received from server at Client: 94 No Estimators: 100\n",
      "Client: 94 trained 200 trees\n",
      "Pruned 47 trees from client 94. Total Trees: 153\n",
      "Estimatorssssssssssssssssssssss 153\n",
      "Trees received from server at Client: 35 No Estimators: 100\n",
      "Client: 35 trained 200 trees\n",
      "Pruned 99 trees from client 35. Total Trees: 101\n",
      "Estimatorssssssssssssssssssssss 101\n",
      "Trees received from server at Client: 31 No Estimators: 100\n",
      "Client: 31 trained 200 trees\n",
      "Pruned 39 trees from client 31. Total Trees: 161\n",
      "Estimatorssssssssssssssssssssss 161\n",
      "Trees received from server at Client: 28 No Estimators: 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m     server.register_client(client)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Run federated training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_federated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mServer.train_federated\u001b[39m\u001b[34m(self, configs)\u001b[39m\n\u001b[32m     59\u001b[39m client_metrics = {}\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m selected_clients:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_trees\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_depth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_max_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_jobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEstimatorssssssssssssssssssssss\u001b[39m\u001b[33m\"\u001b[39m , client.model.n_estimators)\n\u001b[32m     69\u001b[39m     round_models.append(client.model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mClient.train\u001b[39m\u001b[34m(self, num_trees, max_depth, num_max_features, n_jobs)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.model.max_features = num_max_features\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.model.n_jobs = n_jobs\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClient: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.client_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model.n_estimators\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trees\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mself\u001b[39m.prune_redundant_trees() \u001b[38;5;28;01mif\u001b[39;00m configs[\u001b[33m\"\u001b[39m\u001b[33mNUM_CLIENTS\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m configs[\u001b[33m\"\u001b[39m\u001b[33mclient_pruning\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo pruning on client\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/federated-project/fl/lib64/python3.13/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/federated-project/fl/lib64/python3.13/site-packages/sklearn/ensemble/_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/federated-project/fl/lib64/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/federated-project/fl/lib64/python3.13/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/federated-project/fl/lib64/python3.13/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/federated-project/fl/lib64/python3.13/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "global configs\n",
    "configs = {\n",
    "    #Federated Features\n",
    "    \"NUM_CLIENTS\": 100,# If you set the client as 1 it will be centralized training, you should also set the size of val to 0 aswell then\n",
    "    \"clients_per_round\": 10,\n",
    "    \"global_num_trees\": 100,\n",
    "    \"num_rounds\": 20,\n",
    "    \"merge_method\": \"weight_global\",# random, weight_global, weight_voting, impurity, diversity, prune_similar\n",
    "    \"prune_similar\": False,\n",
    "    \"client_pruning\": True,\n",
    "    #Training parameters\n",
    "    \"num_trees\": 200,\n",
    "    \"max_depth\": 4,\n",
    "    \"num_max_features\": 20,\n",
    "    \"n_jobs\": -1,\n",
    "    #Data features partition\n",
    "    \"test_size\": 0.2, \n",
    "    \"val_size\": 0.1, # Should set this to 0 if you are doing centralised training and set test size to 0.3\n",
    "    \"dirichlet_alpha\": 0.8,\n",
    "    #Model parameters\n",
    "    \"criterion\": \"gini\", # or \"entropy\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Load federated data\n",
    "start = timer()\n",
    "client_train_dataset, global_test, global_val, label_encoders = load_federated_data(\n",
    "    num_clients=configs[\"NUM_CLIENTS\"],\n",
    "    alpha=configs[\"dirichlet_alpha\"],\n",
    "    test_size=configs[\"test_size\"],\n",
    "    val_size=configs[\"val_size\"]\n",
    ")\n",
    "end = timer()\n",
    "print(\"Time Elapsed running load data:\", end - start)\n",
    "\n",
    "metrics_tracker = MetricsTracker()\n",
    "\n",
    "# Initialize server\n",
    "server = Server(\n",
    "    num_clients=configs[\"NUM_CLIENTS\"],\n",
    "    clients_per_round=configs[\"clients_per_round\"],\n",
    "    merge_method=configs[\"merge_method\"],\n",
    "    num_global_trees=configs[\"global_num_trees\"],\n",
    "    global_test_data=global_test,\n",
    "    global_val_data=global_val,\n",
    "    prune_similar=configs[\"prune_similar\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Register clients\n",
    "for client_id, client_train in client_train_dataset.items():\n",
    "    client = Client(\n",
    "        client_id,\n",
    "        client_train,       # local training data\n",
    "        global_test,        # global test set\n",
    "        {\"n_estimators\": 0,\n",
    "         \"warm_start\": True,\n",
    "         \"bootstrap\": True,\n",
    "         \"criterion\": configs[\"criterion\"],}\n",
    "    )\n",
    "    server.register_client(client)\n",
    "\n",
    "# Run federated training\n",
    "server.train_federated(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1741201963899,
     "user": {
      "displayName": "Onur Cay",
      "userId": "09681506537499586844"
     },
     "user_tz": 0
    },
    "id": "UmkwQPkNrmbn"
   },
   "outputs": [],
   "source": [
    "#Client specific models so merge for client model and global model at client side.\n",
    "#use the same data set as victor\n",
    "#pruning on client side? maybe if using large data set.\n",
    "#global mode and client model might not be the same.\n",
    "#define client models they will not use the server side model\n",
    "#lit review about fed learning 3 -4 pages random forrest dec trees (2 pgs)\n",
    "# anomly detection related work 3- 4 pages\n",
    "#intro(2) and problem statement (1) goals (1)\n",
    "#describe how you design the system (10) merdging aswell\n",
    "#results analysis tables charts (5pgs)\n",
    "#conclusion future work (2pgs)\n",
    "#thursday 11.30 every week. with victor\n",
    "\n",
    "\n",
    "#I have things that I am not doing. Like privacy or communication overhead. I dont touch on those topics in my implementation.\n",
    "#Should I mention them in my paper especially in the background and say that I am not doing them?\n",
    "#Should this paper be more about an implementation of federated learning rather than the actual federated learning itself? Where I look at experimentation and results?\n",
    "#Challanges of IoT and FL is data is not labelled in real world. What should I write about this? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting Agenda\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Explain what I have so far**\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "- No normalisation, tree models don’t benefit from this.\n",
    "- Drop `attack_cat` as this will be binary exclusively.\n",
    "- Proceed to label string data.\n",
    "- Split the data into train/test/validation sets.\n",
    "- Train data goes through Dirichlet partition.\n",
    "\n",
    "## Server Logic\n",
    "\n",
    "### Clients Setup\n",
    "- Define number of clients.\n",
    "- Define number that train each round.\n",
    "- Server selects clients randomly.\n",
    "\n",
    "### Training\n",
    "- Server trains each client.\n",
    "- Models are just replaced with the global model at client side; there is no averaging or any additional logic.\n",
    "\n",
    "### Merging Methods\n",
    "- I have separate logic for merging with **5 different methods**:\n",
    "  - Random\n",
    "  - Weight_global\n",
    "  - Weight_voting\n",
    "  - Impurity\n",
    "  - Diversity\n",
    "- Also have the option to prune similar trees.\n",
    "\n",
    "## Data Collection and Evaluation\n",
    "\n",
    "### Data Collection Class\n",
    "- Concerned with accuracies and plotting them mainly.\n",
    "\n",
    "### Evaluator Class\n",
    "- Needed because some trees don’t have all the classes so I need to do patching.\n",
    "- This allows sharing code between client and global models.\n",
    "\n",
    "## Tracking Metrics\n",
    "\n",
    "### Per Round\n",
    "- Round number\n",
    "- Accuracy\n",
    "- Recall\n",
    "- ROC AUC\n",
    "- Precision\n",
    "- F1 scores\n",
    "- The clients that participate that round (not sure if this is necessary)\n",
    "\n",
    "### Global Settings (Not Round Specific)\n",
    "- Number of trees that server gives to clients\n",
    "- Number of trees the clients train up to\n",
    "- Merge method being used\n",
    "- Number of clients participating\n",
    "- Criterion \n",
    "- (whether using pruning or not on server)\n",
    "\n",
    "### Additional Tracking\n",
    "- Client distributions for each experiment to show non-IIDness.\n",
    "\n",
    "## Experiment Considerations\n",
    "\n",
    "### Parameters to Vary\n",
    "- Tree parameters (start with fewer/more trees)\n",
    "- Merge method being used\n",
    "- Criterion \n",
    "- (pruning on the server or not)\n",
    "- Max depth and Max features (unsure if these are useful in federated learning)\n",
    "\n",
    "### Request for Input\n",
    "- Would like suggestions on what exactly to focus on during experiments.\n",
    "- Should client selection and partitioning be deterministic for experiments. I feel like it should be. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO7xXoJg7R8qVPIaBIfQRyv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01dbbc6827d14c868adaca883a806d3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "027f732d3ff44cab9435cf393c970126": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "051643c631914823943d26107ebfbfe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_07f3f85160624a79a201b0b74f7a12ef",
       "IPY_MODEL_0a93e69a9c8a4043bc6b2734e62a26f8",
       "IPY_MODEL_25bfe18481704dcb88e542208fb4d611"
      ],
      "layout": "IPY_MODEL_7e06ff0338164874a7ada4759649640c"
     }
    },
    "0676fbda5810459781d3bfcc05a1b3a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07f3f85160624a79a201b0b74f7a12ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aa19145ed694cbeaf2e74217dcdb6d1",
      "placeholder": "​",
      "style": "IPY_MODEL_abf26fc0ec744b249d63f32a6ee17b46",
      "value": "test.csv: 100%"
     }
    },
    "0993a3dc159e4d318610a7b89e092e65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a93e69a9c8a4043bc6b2734e62a26f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dab394178e645af8fc20d80692e39be",
      "max": 32293018,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e7a950fb99d4af287a01100ae972c32",
      "value": 32293018
     }
    },
    "0cdc971c598d42fd9a46a0303357ceac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4dc453d3206149ba8b32f66ab74bbc03",
      "max": 82332,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4bc1347503940f09e79bcfedd38ba2c",
      "value": 0
     }
    },
    "0eb7d12293fe4795a223b86f709f41e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01dbbc6827d14c868adaca883a806d3d",
      "placeholder": "​",
      "style": "IPY_MODEL_44c06f599fee445a8d52877df1f74e1f",
      "value": "Generating train split: 100%"
     }
    },
    "1b0b68608a2244edb9681a10af7063b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ec1acde58d74c31bd27c05c1a05dc00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "236f61f845c74fc584ee1047f739094c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c605c8b8ef96463aa00f8e4367fee2db",
       "IPY_MODEL_3d5a46c2c6cb46b8801ca26b0fa19ca7",
       "IPY_MODEL_88c4b7ce3de84950a7a58a765ea34f3b"
      ],
      "layout": "IPY_MODEL_7832e63390ba47d6b747c569ca44d485"
     }
    },
    "2524b3c9c7da4f3fafcdbc9f39226b75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dd5e03466794d5a84a0e7dc776af541",
      "placeholder": "​",
      "style": "IPY_MODEL_69d321e4bcda4d11811a5406d33806d8",
      "value": " 0/82332 [00:00&lt;?, ? examples/s]"
     }
    },
    "25537b892b1d4202bc1708c2c220d20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_259af56bcf404b9f979be892612ce575",
      "max": 15380800,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fc563b13aa0a43adaa00fa00b27f53c0",
      "value": 15380800
     }
    },
    "259af56bcf404b9f979be892612ce575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25bfe18481704dcb88e542208fb4d611": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0676fbda5810459781d3bfcc05a1b3a1",
      "placeholder": "​",
      "style": "IPY_MODEL_77dcd4929e424ff6a08b6a5e36a455d1",
      "value": " 32.3M/32.3M [00:00&lt;00:00, 59.9MB/s]"
     }
    },
    "35759d22a66e4d86bf222f9c512fb26d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "371a5ea3867c40f4b09f29d885840858": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d915e805716644918d53d9e7194c23d1",
      "placeholder": "​",
      "style": "IPY_MODEL_027f732d3ff44cab9435cf393c970126",
      "value": " 175341/175341 [00:02&lt;00:00, 85241.42 examples/s]"
     }
    },
    "380ae28d07b84eeeb40eaec04e110ce6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d5a46c2c6cb46b8801ca26b0fa19ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b0b68608a2244edb9681a10af7063b4",
      "max": 1876,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_538be84d21884997b5a67411ebc84434",
      "value": 1876
     }
    },
    "43e6f98d4d864753b7e5edb68b759722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a2ec98eb4b64dd4b0c889e1b9ecf5a1",
      "max": 82332,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c55be10eeb6c4bbf94d8c84c7af6fa66",
      "value": 82332
     }
    },
    "44c06f599fee445a8d52877df1f74e1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a7d6c0afbff4daba41492fc5202d8ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4aa19145ed694cbeaf2e74217dcdb6d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dc453d3206149ba8b32f66ab74bbc03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e7a950fb99d4af287a01100ae972c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "538be84d21884997b5a67411ebc84434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5dab394178e645af8fc20d80692e39be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69d321e4bcda4d11811a5406d33806d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e728d14df204639a53627d863dc992f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73ec19ee745b4bb89a29942595ba51e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bcfe2703c874c218f699e78e436f618",
      "max": 175341,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eff344cf223946a89f0ca7e1e929a97f",
      "value": 175341
     }
    },
    "776d311d33bb492f8f6766cc2796b44f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77dcd4929e424ff6a08b6a5e36a455d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7832e63390ba47d6b747c569ca44d485": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dd5e03466794d5a84a0e7dc776af541": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e06ff0338164874a7ada4759649640c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88c4b7ce3de84950a7a58a765ea34f3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a491f1d6c1944e688cb55fab0c27ce91",
      "placeholder": "​",
      "style": "IPY_MODEL_35759d22a66e4d86bf222f9c512fb26d",
      "value": " 1.88k/1.88k [00:00&lt;00:00, 40.1kB/s]"
     }
    },
    "8a2ec98eb4b64dd4b0c889e1b9ecf5a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c75ae5c8ee648b593c6e784d923c95f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e58a06edaae54dbc88879347bd99b0e0",
      "placeholder": "​",
      "style": "IPY_MODEL_adfd95ebaa964a709cfbce42891c68c1",
      "value": "Generating test split: 100%"
     }
    },
    "8cf4285da9104612895b4cf1378e87a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93eeff87e78147c38b9ac1286debd53b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1d5833c759c406db33696415842e532",
      "placeholder": "​",
      "style": "IPY_MODEL_bb9d0339257f479682a36daaa8fe1c84",
      "value": "train.csv: 100%"
     }
    },
    "9bcfe2703c874c218f699e78e436f618": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1d5833c759c406db33696415842e532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a251b19360a64041b1d0222165845246": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c75ae5c8ee648b593c6e784d923c95f",
       "IPY_MODEL_73ec19ee745b4bb89a29942595ba51e6",
       "IPY_MODEL_371a5ea3867c40f4b09f29d885840858"
      ],
      "layout": "IPY_MODEL_e6566d36061548599aa7f742f5c640e6"
     }
    },
    "a491f1d6c1944e688cb55fab0c27ce91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4bc1347503940f09e79bcfedd38ba2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5f0a493bc114963ac372efe419af80c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_776d311d33bb492f8f6766cc2796b44f",
      "placeholder": "​",
      "style": "IPY_MODEL_d170008ddd8049b1bbb095579ab72ee8",
      "value": " 15.4M/15.4M [00:00&lt;00:00, 30.1MB/s]"
     }
    },
    "abf26fc0ec744b249d63f32a6ee17b46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac58bc9084744bbb95e9f8a6d225f66c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93eeff87e78147c38b9ac1286debd53b",
       "IPY_MODEL_25537b892b1d4202bc1708c2c220d20a",
       "IPY_MODEL_a5f0a493bc114963ac372efe419af80c"
      ],
      "layout": "IPY_MODEL_6e728d14df204639a53627d863dc992f"
     }
    },
    "adfd95ebaa964a709cfbce42891c68c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb9d0339257f479682a36daaa8fe1c84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be19d56b5324423d9506c2bf9b8fd733": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cf4285da9104612895b4cf1378e87a0",
      "placeholder": "​",
      "style": "IPY_MODEL_4a7d6c0afbff4daba41492fc5202d8ac",
      "value": "Map:   0%"
     }
    },
    "c55be10eeb6c4bbf94d8c84c7af6fa66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c605c8b8ef96463aa00f8e4367fee2db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da13000f510c4b289ef4988a2f0f03ae",
      "placeholder": "​",
      "style": "IPY_MODEL_f299f4c6b7f94becba1604779ea76196",
      "value": "README.md: 100%"
     }
    },
    "ce256d87f7d14c84b6796507b9a94c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3bfb768d8c147fc94a501742455f84b",
      "placeholder": "​",
      "style": "IPY_MODEL_1ec1acde58d74c31bd27c05c1a05dc00",
      "value": " 82332/82332 [00:02&lt;00:00, 32796.42 examples/s]"
     }
    },
    "d170008ddd8049b1bbb095579ab72ee8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d915e805716644918d53d9e7194c23d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da13000f510c4b289ef4988a2f0f03ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e58a06edaae54dbc88879347bd99b0e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6566d36061548599aa7f742f5c640e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb4a4f9b49d44884b15de653563c48e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be19d56b5324423d9506c2bf9b8fd733",
       "IPY_MODEL_0cdc971c598d42fd9a46a0303357ceac",
       "IPY_MODEL_2524b3c9c7da4f3fafcdbc9f39226b75"
      ],
      "layout": "IPY_MODEL_0993a3dc159e4d318610a7b89e092e65"
     }
    },
    "eff344cf223946a89f0ca7e1e929a97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f299f4c6b7f94becba1604779ea76196": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3bfb768d8c147fc94a501742455f84b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc563b13aa0a43adaa00fa00b27f53c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe2913e5edd04126b8acda473261a37b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0eb7d12293fe4795a223b86f709f41e0",
       "IPY_MODEL_43e6f98d4d864753b7e5edb68b759722",
       "IPY_MODEL_ce256d87f7d14c84b6796507b9a94c85"
      ],
      "layout": "IPY_MODEL_380ae28d07b84eeeb40eaec04e110ce6"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
