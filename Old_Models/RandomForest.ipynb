{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bMZr9ou4YETs"},"outputs":[],"source":["!pip install -q flwr[simulation] flwr-datasets[vision] datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19922,"status":"ok","timestamp":1737557637786,"user":{"displayName":"Onur Cay","userId":"09681506537499586844"},"user_tz":0},"id":"ECtXMOfXYHPt","outputId":"c4ae8aa6-cc6b-4416-fac7-b642aae86909"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on cuda\n","Flower 1.14.0 / PyTorch 2.5.1+cu121\n"]}],"source":["from collections import OrderedDict, defaultdict\n","from datasets import DatasetDict, Dataset\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim.lr_scheduler as lr_scheduler\n","from datasets.utils.logging import disable_progress_bar\n","from torch.utils.data import DataLoader\n","\n","import flwr\n","from flwr.client import Client, ClientApp, NumPyClient\n","from flwr.common import Metrics, Context\n","from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n","from flwr.server.strategy import FedAvg\n","from flwr.simulation import run_simulation\n","from flwr_datasets import FederatedDataset\n","\n","DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n","print(f\"Training on {DEVICE}\")\n","print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n","disable_progress_bar()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1737557637786,"user":{"displayName":"Onur Cay","userId":"09681506537499586844"},"user_tz":0},"id":"W0QWYklag40h","outputId":"fbeeb570-a2ae-4e67-b1a8-41354892fb2f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["def normalize_dataset(dataset_dict):\n","    \"\"\"\n","    Normalize all numerical features in each split of the DatasetDict while retaining the original structure.\n","\n","    Args:\n","        dataset_dict (DatasetDict): The dataset with splits (e.g., train, test).\n","\n","    Returns:\n","        DatasetDict: A new DatasetDict with normalized features.\n","    \"\"\"\n","\n","    def normalize_split(split_dataset):\n","        feature_keys = [key for key in split_dataset.column_names if key != \"is_spam\"]  # Exclude the label\n","        features = np.array([split_dataset[key] for key in feature_keys]).T  # Extract features as a matrix\n","        labels = split_dataset[\"is_spam\"]  # Extract labels\n","\n","        # Apply Min-Max Scaling\n","        scaler = MinMaxScaler()\n","        normalized_features = scaler.fit_transform(features)\n","\n","        # Create a dictionary for normalized data\n","        normalized_data = {key: normalized_features[:, idx] for idx, key in enumerate(feature_keys)}\n","        normalized_data[\"is_spam\"] = labels  # Retain the labels\n","\n","        # Convert back to a Dataset\n","        return split_dataset.from_dict(normalized_data)\n","\n","    # Normalize each split (e.g., train, validation, test)\n","    normalized_splits = {split_name: normalize_split(split) for split_name, split in dataset_dict.items()}\n","\n","    # Return the new normalized DatasetDict\n","    return normalized_splits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gpdgjhGuulp"},"outputs":[],"source":["\n","global_partitions = {}\n","\n","def preload_datasets():\n","    \"\"\"Preload and partition the dataset into global_partitions.\"\"\"\n","    global global_partitions\n","    fds = FederatedDataset(dataset=\"mstz/spambase\", partitioners={\"train\":configs[\"NUM_CLIENTS\"]}, preprocessor=normalize_dataset)\n","    for partition_id in range(configs[\"NUM_CLIENTS\"]):\n","        partition = fds.load_partition(partition_id)\n","        train_test_split = partition.train_test_split(test_size=configs[\"test_size\"], seed=configs[\"seed\"])\n","        train_val_split = train_test_split[\"train\"].train_test_split(test_size=configs[\"test_size\"], seed=configs[\"seed\"])\n","\n","        global_partitions[partition_id] = {\n","            \"train\": DataLoader(train_val_split[\"train\"], batch_size=configs[\"BATCH_SIZE\"], shuffle=True),\n","            \"val\": DataLoader(train_val_split[\"test\"], batch_size=configs[\"BATCH_SIZE\"]),\n","            \"test\": DataLoader(train_test_split[\"test\"], batch_size=configs[\"BATCH_SIZE\"]),\n","        }\n","\n","#Non-IID data. DirichletPartitioner"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Me_skoQaO9tj"},"outputs":[],"source":["class SoftDecisionTree(nn.Module):\n","    def __init__(self, input_size, depth=3, output_size=2, temperature=1.0,feature_subset=None):\n","        super(SoftDecisionTree, self).__init__()\n","        self.depth = depth\n","        self.num_nodes = 2 ** depth - 1  # Number of decision nodes\n","        self.num_leaves = 2 ** depth    # Number of leaf nodes\n","        self.temperature = temperature\n","        self.feature_subset = feature_subset\n","\n","\n","        actual_input_size = len(feature_subset) if feature_subset else input_size\n","\n","        self.dropout = nn.Dropout(p=0.2)\n","        # Decision nodes (cut points for splits)\n","        self.decision_nodes = nn.ModuleList([\n","            nn.Linear(actual_input_size, 1) for _ in range(self.num_nodes)\n","        ])\n","\n","        # Leaf scores (probabilities for classification)\n","        self.leaf_scores = nn.Linear(self.num_leaves, output_size)\n","\n","    def forward(self, x):\n","\n","        if self.feature_subset:\n","            x = x[:, self.feature_subset]\n","\n","        x = self.dropout(x)\n","        # Compute probabilities for each decision node\n","        decision_probs = torch.cat([torch.sigmoid(node(x)) for node in self.decision_nodes], dim=1)\n","\n","        # Compute leaf probabilities\n","        leaf_probs = self.compute_leaf_probs(decision_probs)\n","\n","        # Compute class probabilities\n","        output = self.leaf_scores(leaf_probs)\n","\n","\n","        #return F.log_softmax(output, dim=1)\n","        return output\n","\n","\n","    def compute_leaf_probs(self, decision_probs):\n","      \"\"\"\n","      Compute the probabilities for each leaf node using the decision probabilities.\n","      \"\"\"\n","      batch_size = decision_probs.size(0)\n","      leaf_probs = torch.ones(batch_size, self.num_leaves, device=decision_probs.device)\n","\n","      for depth in range(self.depth):\n","          stride = 2 ** (self.depth - depth - 1)\n","          for leaf_idx in range(0, self.num_leaves, stride * 2):\n","              node_idx = (2 ** depth - 1) + (leaf_idx // (stride * 2))\n","\n","              # Ensure alignment of shapes\n","              decision_prob = decision_probs[:, node_idx].unsqueeze(1)  # Shape [batch_size, 1]\n","              complement_prob = (1 - decision_prob)  # Shape [batch_size, 1]\n","\n","              # Update probabilities\n","              leaf_probs[:, leaf_idx:leaf_idx + stride] *= decision_prob\n","              leaf_probs[:, leaf_idx + stride:leaf_idx + stride * 2] *= complement_prob\n","\n","      return leaf_probs\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssTch5nFAhji"},"outputs":[],"source":["class SoftRandomForest(nn.Module):\n","    def __init__(self, num_trees, input_size, depth=3, output_size=2, temperature=1.0, num_features=None):\n","        super(SoftRandomForest, self).__init__()\n","        self.num_trees = num_trees\n","        self.trees = nn.ModuleList([\n","            SoftDecisionTree(\n","                input_size=input_size,\n","                depth=depth,\n","                output_size=output_size,\n","                temperature=temperature,\n","                feature_subset=torch.randperm(input_size)[:num_features].tolist() if num_features else None\n","            ) for _ in range(num_trees)\n","        ])\n","\n","    def forward(self, x):\n","        # Collect predictions from all trees\n","        tree_outputs = torch.stack([tree(x) for tree in self.trees], dim=0)  # Shape: [num_trees, batch_size, output_size]\n","\n","        # Average probabilities for classification\n","        avg_output = torch.mean(tree_outputs, dim=0)  # Shape: [batch_size, output_size]\n","        return avg_output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASqtHiXchfbp"},"outputs":[],"source":["def train_forest(forest, trainloader, epochs, lr):\n","    \"\"\"Train the Soft Random Forest.\"\"\"\n","\n","    criterion = nn.CrossEntropyLoss()\n","    #criterion = nn.NLLLoss()\n","\n","    optimizers = [\n","        torch.optim.Adam(tree.parameters(), lr=lr, weight_decay=1e-4) for tree in forest.trees\n","    ]\n","\n","    schedulers = [\n","        torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n","        for optimizer in optimizers\n","    ]\n","\n","    all_inputs = []\n","    all_labels = []\n","    for batch in trainloader:\n","        inputs = torch.stack([value for key, value in batch.items() if key != \"is_spam\"], dim=1).float()\n","        labels = batch[\"is_spam\"].long()\n","        all_inputs.append(inputs)\n","        all_labels.append(labels)\n","\n","    all_inputs = torch.cat(all_inputs, dim=0)\n","    all_labels = torch.cat(all_labels, dim=0)\n","\n","    tree_data = []\n","    for tree_idx in range(len(forest.trees)):\n","        indices = torch.randint(0, len(all_inputs), (len(all_inputs),))  # Bootstrap sampling\n","        inputs_bootstrap = all_inputs[indices]\n","        labels_bootstrap = all_labels[indices]\n","        inputs_bootstrap = (inputs_bootstrap - inputs_bootstrap.mean(dim=0)) / (inputs_bootstrap.std(dim=0) + 1e-8)#Normalize\n","        if tree_idx == 0:\n","          print(f\"[DEBUG] Labels bootstrap sample: {labels_bootstrap[:10]}\")\n","\n","        # Store data for the tree\n","        tree_data.append((inputs_bootstrap, labels_bootstrap))\n","\n","\n","    best_losses = [float(\"inf\")] * len(forest.trees)\n","    patience_counters = [0] * len(forest.trees)\n","\n","    for epoch in range(epochs):\n","        total_loss, correct, total = 0.0, 0, 0\n","\n","        # Train each tree independently\n","        for tree_idx, (tree, optimizer, scheduler) in enumerate(zip(forest.trees, optimizers,schedulers)):\n","            tree.train()\n","\n","\n","\n","            inputs_bootstrap, labels_bootstrap = tree_data[tree_idx]\n","            epoch_loss = 0.0\n","\n","            for batch_idx, batch in enumerate(trainloader):\n","                if epoch == 0 and tree_idx == 0 and batch_idx == 0:\n","                  print(f\"[DEBUG] First decision node weights (Tree 0): {tree.decision_nodes[0].weight.data}\")\n","                  print(f\"[DEBUG] Inputs mean: {inputs_bootstrap.mean():.4f}, std: {inputs_bootstrap.std():.4f}\")\n","\n","                # Zero gradients\n","                optimizer.zero_grad()\n","\n","                # Forward pass\n","                outputs = tree(inputs_bootstrap)\n","                if epoch == 0 and tree_idx == 0 and batch_idx == 0:\n","                  print(f\"[DEBUG] Outputs sample logits: {outputs[:5]}\")\n","\n","                loss = criterion(outputs, labels_bootstrap)\n","\n","                # Backward pass and optimization\n","                loss.backward()\n","                optimizer.step()\n","\n","                # Track metrics\n","                epoch_loss += loss.item()\n","                total_loss += loss.item()\n","                _, predicted = torch.max(outputs, dim=1)\n","                total += labels_bootstrap.size(0)\n","                correct += (predicted == labels_bootstrap).sum().item()\n","\n","            #Scheduler step\n","            avg_epoch_loss = (epoch_loss / len(trainloader))\n","            scheduler.step()\n","            #if True:\n","              #print(f\"[DEBUG] Learning rate after scheduler step (Tree {tree_idx}): {optimizer.param_groups[0]['lr']}\")\n","\n","            # Early Stopping Logic\n","            min_delta = configs[\"min_delta\"]\n","            if total_loss < best_losses[tree_idx] - min_delta:\n","                best_losses[tree_idx] = total_loss\n","                patience_counters[tree_idx] = 0\n","            else:\n","                patience_counters[tree_idx] += 1\n","\n","            if patience_counters[tree_idx] >= configs[\"patience\"]:\n","                print(f\"Tree {tree_idx}: Early stopping at epoch {epoch + 1}\")\n","                break\n","\n","\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {100 * correct / total:.2f}%\")\n","\n","\n","def test_forest(forest, testloader):\n","    \"\"\"Evaluate the Soft Random Forest on the test set.\"\"\"\n","    #criterion = nn.NLLLoss()\n","    criterion = nn.CrossEntropyLoss()\n","    forest.eval()\n","    total_loss, correct, total = 0.0, 0, 0\n","\n","    with torch.no_grad():\n","        for batch in testloader:\n","            # Extract features and labels\n","            inputs = torch.stack([value for key, value in batch.items() if key != \"is_spam\"], dim=1).float()\n","            labels = batch[\"is_spam\"].long()\n","\n","            # Get predictions from the forest\n","            outputs = forest(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # Track metrics\n","            total_loss += loss.item()\n","            _, predicted = torch.max(outputs, dim=1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    return total_loss / len(testloader.dataset), accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78xut7azqNOL"},"outputs":[],"source":["class FederatedClient(NumPyClient):\n","    def __init__(self, model, trainloader, testloader):\n","        self.model = model\n","        self.trainloader = trainloader\n","        self.testloader = testloader\n","\n","    def get_parameters(self, config=None):\n","        \"\"\"Get model parameters as a list of NumPy arrays.\"\"\"\n","        params = [param.cpu().detach().numpy() for param in self.model.parameters()]\n","        #print(f\"[DEBUG] Parameters being sent back to the server: {[p.shape for p in params]}\")\n","        return params\n","    def set_parameters(self, parameters):\n","        \"\"\"Set model parameters from a list of NumPy arrays.\"\"\"\n","        params_dict = zip(self.model.state_dict().keys(), parameters)\n","        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n","        self.model.load_state_dict(state_dict, strict=True)\n","        #print(f\"[DEBUG] Parameters received from the server set successfully.\")\n","\n","    def fit(self, parameters, config):\n","        \"\"\"Train the model on the local dataset.\"\"\"\n","        #print(f\"[DEBUG] Starting training on client with {len(self.trainloader.dataset)} samples.\")\n","        self.set_parameters(parameters)\n","        lr = config.get(\"lr\", configs[\"lr\"])\n","        local_epochs = config.get(\"local_epochs\", configs[\"local_epochs\"])\n","\n","        train_forest(self.model, self.trainloader, epochs=local_epochs, lr=lr)\n","        return self.get_parameters(), len(self.trainloader.dataset), {}\n","\n","    def evaluate(self, parameters, config):\n","        \"\"\"Evaluate the model on the local test set.\"\"\"\n","        self.set_parameters(parameters)\n","        loss, accuracy = test_forest(self.model, self.testloader)\n","        #print(f\"[DEBUG] Evaluation results - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n","        return float(loss), len(self.testloader.dataset), {\"accuracy\": float(accuracy)}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmkwQPkNrmbn"},"outputs":[],"source":["def weighted_average(metrics):\n","    \"\"\"Aggregate metrics from multiple clients.\"\"\"\n","    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n","    total_examples = [num_examples for num_examples, _ in metrics]\n","    return {\"accuracy\": sum(accuracies) / sum(total_examples)}\n","\n","def server_fn(context):\n","    def on_fit_config_fn(round_num):\n","      #print(f\"[DEBUG] Starting Round {round_num} with configuration.\")\n","      return {\"lr\": configs[\"lr\"], \"local_epochs\": configs[\"local_epochs\"]}\n","\n","\n","    \"\"\"Server configuration for federated learning.\"\"\"\n","    strategy = FedAvg(\n","        fraction_fit=1.0,\n","        fraction_evaluate=0.5,\n","        min_fit_clients=configs[\"NUM_CLIENTS\"],\n","        min_evaluate_clients=1,\n","        min_available_clients=configs[\"NUM_CLIENTS\"],\n","        on_fit_config_fn=on_fit_config_fn,\n","        evaluate_metrics_aggregation_fn=weighted_average,\n","    )\n","    return flwr.server.ServerAppComponents(strategy=strategy, config=ServerConfig(num_rounds=configs[\"num_rounds\"]))\n","#Get models from clients and merge the models. Then evaluate the global model.\n","#Use sklearn to define the models. Probnably dont use flower. Use flower for partitoning. Code is custom mainly.\n","#Sort and select for merging.\n","#Random forrest has diffrent depths and shapes. So how do you merge it?\n","#Not all clients participate in training but they all get the same model\n","#How do we push the model?\n","#Eval data set is used to sort. To determine which trees are good.\n","#MDT, sort and select, no merging you select the trees to form a forrest."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"n_6sdyagqePT","outputId":"07c61c05-74f8-446c-f632-516c1b163efd"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/flwr_datasets/utils.py:109: UserWarning: The currently tested dataset are ['mnist', 'ylecun/mnist', 'cifar10', 'uoft-cs/cifar10', 'fashion_mnist', 'zalando-datasets/fashion_mnist', 'sasha/dog-food', 'zh-plus/tiny-imagenet', 'scikit-learn/adult-census-income', 'cifar100', 'uoft-cs/cifar100', 'svhn', 'ufldl-stanford/svhn', 'sentiment140', 'stanfordnlp/sentiment140', 'speech_commands', 'LIUM/tedlium', 'flwrlabs/femnist', 'flwrlabs/ucf101', 'flwrlabs/ambient-acoustic-context', 'jlh/uci-mushrooms', 'Mike0307/MNIST-M', 'flwrlabs/usps', 'scikit-learn/iris', 'flwrlabs/pacs', 'flwrlabs/cinic10', 'flwrlabs/caltech101', 'flwrlabs/office-home', 'flwrlabs/fed-isic2019']. Given: mstz/spambase.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","DEBUG:flwr:Asyncio event loop already running.\n","\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=8, no round_timeout\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [INIT]\n","\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n","\u001b[36m(pid=8244)\u001b[0m 2025-01-22 14:54:18.615022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(pid=8244)\u001b[0m 2025-01-22 14:54:18.704383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(pid=8244)\u001b[0m 2025-01-22 14:54:18.732933: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(pid=8244)\u001b[0m 2025-01-22 14:54:22.330093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n","\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n","\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 1]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.1452, -0.0961,  0.1771,  0.1246,  0.1010, -0.0358,  0.0051, -0.0428,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0541, -0.1640,  0.1233, -0.1680, -0.0419,  0.1033, -0.0361,  0.0948,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m          -0.0921, -0.1659,  0.1253, -0.0189, -0.1496,  0.0902, -0.1132, -0.1106,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.1105]])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: 0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.2378, -0.2366],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2463, -0.2481],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2212, -0.2747],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2394, -0.2773],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2132, -0.2730]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.1452, -0.0961,  0.1771,  0.1246,  0.1010, -0.0358,  0.0051, -0.0428,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0541, -0.1640,  0.1233, -0.1680, -0.0419,  0.1033, -0.0361,  0.0948,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.0921, -0.1659,  0.1253, -0.0189, -0.1496,  0.0902, -0.1132, -0.1106,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.1105]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.2365, -0.2729],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.2389, -0.2761],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.2476, -0.2672],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.2409, -0.2864],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.2365, -0.2672]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [1/10], Loss: 270.9907, Accuracy: 57.25%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 271.6328, Accuracy: 56.72%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [2/10], Loss: 252.4815, Accuracy: 64.89%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 254.1550, Accuracy: 64.23%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [3/10], Loss: 235.3141, Accuracy: 68.24%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 237.2993, Accuracy: 69.47%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [4/10], Loss: 219.5708, Accuracy: 75.11%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 221.8593, Accuracy: 76.40%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [5/10], Loss: 206.6587, Accuracy: 79.81%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 209.2964, Accuracy: 80.28%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [6/10], Loss: 196.9657, Accuracy: 82.15%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [7/10], Loss: 190.6211, Accuracy: 83.21%\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [8/10], Loss: 186.4593, Accuracy: 83.83%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [9/10], Loss: 184.4076, Accuracy: 84.09%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [10/10], Loss: 183.5210, Accuracy: 84.22%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.1452, -0.0961,  0.1771,  0.1246,  0.1010, -0.0358,  0.0051, -0.0428,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0541, -0.1640,  0.1233, -0.1680, -0.0419,  0.1033, -0.0361,  0.0948,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m          -0.0921, -0.1659,  0.1253, -0.0189, -0.1496,  0.0902, -0.1132, -0.1106,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.1105]])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.2648, -0.2141],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2361, -0.2718],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2498, -0.2687],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2212, -0.2585],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2638, -0.2547]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [1/10], Loss: 272.0664, Accuracy: 56.59%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [2/10], Loss: 254.9857, Accuracy: 63.70%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [3/10], Loss: 238.9081, Accuracy: 68.48%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [4/10], Loss: 223.9753, Accuracy: 75.20%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [5/10], Loss: 211.5891, Accuracy: 79.32%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [6/10], Loss: 202.6039, Accuracy: 81.16%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [7/10], Loss: 196.2938, Accuracy: 82.19%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [8/10], Loss: 192.3745, Accuracy: 82.71%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [9/10], Loss: 190.5658, Accuracy: 82.86%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [10/10], Loss: 189.6306, Accuracy: 82.95%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n","\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 2]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.0788,  0.0581,  0.6089,  0.1547, -0.0216, -0.1907, -0.0761, -0.0702,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0860, -0.2780,  0.3245, -0.1739, -0.2066,  0.3093,  0.3336,  0.1791,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m          -0.1615, -0.0819,  0.2605,  0.2313,  0.0090,  0.2416,  0.1476, -0.1353,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0868]])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.0831, -0.6131],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.2641, -0.8316],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.5819,  0.1670],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.3108, -0.8666],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.1124, -0.6271]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [1/10], Loss: 254.7577, Accuracy: 64.35%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.0788,  0.0581,  0.6089,  0.1547, -0.0216, -0.1907, -0.0761, -0.0702,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0868]])\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.2094, -0.7581],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.1427, -0.6385]], grad_fn=<SliceBackward0>)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [2/10], Loss: 227.9190, Accuracy: 71.47%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 209.3480, Accuracy: 76.90%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 194.4025, Accuracy: 79.62%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 183.5243, Accuracy: 81.47%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [6/10], Loss: 172.2205, Accuracy: 83.45%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [7/10], Loss: 166.9976, Accuracy: 84.12%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [8/10], Loss: 164.3367, Accuracy: 84.41%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [9/10], Loss: 162.4538, Accuracy: 84.64%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [10/10], Loss: 161.7702, Accuracy: 84.73%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.0788,  0.0581,  0.6089,  0.1547, -0.0216, -0.1907, -0.0761, -0.0702,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0860, -0.2780,  0.3245, -0.1739, -0.2066,  0.3093,  0.3336,  0.1791,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m          -0.1615, -0.0819,  0.2605,  0.2313,  0.0090,  0.2416,  0.1476, -0.1353,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0868]])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.3439, -0.2470],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.0550, -0.4709],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.1829, -0.7056],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.0895, -0.6276],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.0523, -0.5674]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [1/10], Loss: 262.9061, Accuracy: 61.64%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [2/10], Loss: 235.4910, Accuracy: 70.22%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [3/10], Loss: 214.3732, Accuracy: 76.22%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [4/10], Loss: 198.4285, Accuracy: 79.47%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [5/10], Loss: 186.8603, Accuracy: 81.39%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [6/10], Loss: 178.8003, Accuracy: 82.44%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [7/10], Loss: 173.6961, Accuracy: 83.12%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [8/10], Loss: 170.8220, Accuracy: 83.41%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [9/10], Loss: 168.9884, Accuracy: 83.62%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [10/10], Loss: 168.5432, Accuracy: 83.67%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 3]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.4131, -0.0576,  0.1760,  0.0292,  0.1447,  0.0342,  0.2312, -0.4197,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0863, -0.6120,  0.1139, -0.0612, -0.3003,  0.4199,  0.6000,  0.0292,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.0083, -0.3015,  0.1794,  0.1112, -0.3171,  0.4274,  0.1356,  0.0063,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.3066]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.1630, -0.3512],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.4016, -0.8967],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.0262, -0.4917],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.1312, -0.5893],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.0917, -0.4064]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 257.0492, Accuracy: 65.31%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.4131, -0.0576,  0.1760,  0.0292,  0.1447,  0.0342,  0.2312, -0.4197,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.5513,  0.0780],\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.0535, -0.4540],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.0447, -0.5438]], grad_fn=<SliceBackward0>)\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 219.4020, Accuracy: 73.16%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [3/10], Loss: 198.5906, Accuracy: 77.74%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [4/10], Loss: 184.0755, Accuracy: 80.20%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 168.9330, Accuracy: 82.89%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 161.7912, Accuracy: 83.97%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [7/10], Loss: 163.9326, Accuracy: 83.16%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [8/10], Loss: 161.7893, Accuracy: 83.43%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [9/10], Loss: 160.2569, Accuracy: 83.62%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 152.2747, Accuracy: 85.21%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.4131, -0.0576,  0.1760,  0.0292,  0.1447,  0.0342,  0.2312, -0.4197,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0863, -0.6120,  0.1139, -0.0612, -0.3003,  0.4199,  0.6000,  0.0292,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.0083, -0.3015,  0.1794,  0.1112, -0.3171,  0.4274,  0.1356,  0.0063,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.3066]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: 0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.1171, -0.6180],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0103, -0.5227],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0408, -0.5380],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.8858,  0.4278],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.1407, -0.6402]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 262.3470, Accuracy: 63.61%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 227.1295, Accuracy: 71.57%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 204.4516, Accuracy: 76.39%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 189.5674, Accuracy: 79.15%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 179.3870, Accuracy: 80.95%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 172.5217, Accuracy: 81.98%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 168.3659, Accuracy: 82.63%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 165.5859, Accuracy: 83.00%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 164.0642, Accuracy: 83.25%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 163.6263, Accuracy: 83.22%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 4]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.3863,  0.0068,  0.4511,  0.3364,  0.2170,  0.1916,  0.0877, -0.1702,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0538, -0.5705, -0.0505, -0.1740, -0.1669,  0.3080,  0.4159, -0.1933,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0399, -0.1901,  0.2473, -0.1654, -0.1084,  0.0526,  0.2185, -0.0817,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.1006]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.1994, -0.3004],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.6971,  0.2362],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.7742, -1.2738],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.2941, -0.1975],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0085, -0.5283]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [1/10], Loss: 262.9389, Accuracy: 64.79%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.3863,  0.0068,  0.4511,  0.3364,  0.2170,  0.1916,  0.0877, -0.1702,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.1006]])\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-4.9738e-01, -1.3510e-03],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 9.6343e-02, -6.5664e-01]], grad_fn=<SliceBackward0>)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [2/10], Loss: 215.8916, Accuracy: 73.92%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [3/10], Loss: 188.7044, Accuracy: 78.97%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [4/10], Loss: 172.4397, Accuracy: 81.76%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [5/10], Loss: 162.4053, Accuracy: 83.40%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [6/10], Loss: 155.9673, Accuracy: 84.34%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [7/10], Loss: 151.6632, Accuracy: 84.95%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [8/10], Loss: 149.3478, Accuracy: 85.26%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [9/10], Loss: 148.0556, Accuracy: 85.41%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [10/10], Loss: 147.4214, Accuracy: 85.51%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.3863,  0.0068,  0.4511,  0.3364,  0.2170,  0.1916,  0.0877, -0.1702,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0538, -0.5705, -0.0505, -0.1740, -0.1669,  0.3080,  0.4159, -0.1933,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.0399, -0.1901,  0.2473, -0.1654, -0.1084,  0.0526,  0.2185, -0.0817,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.1006]])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.1345, -0.6289],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.2462, -0.7505],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.7561,  0.2755],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.6507, -1.1370],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.1208, -0.3711]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 154.0107, Accuracy: 84.30%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [1/10], Loss: 271.8158, Accuracy: 62.31%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [2/10], Loss: 223.5498, Accuracy: 72.44%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [3/10], Loss: 195.8024, Accuracy: 78.00%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [4/10], Loss: 179.5129, Accuracy: 80.87%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [5/10], Loss: 168.9704, Accuracy: 82.51%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [6/10], Loss: 162.4544, Accuracy: 83.35%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [7/10], Loss: 157.9288, Accuracy: 83.98%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [8/10], Loss: 155.7453, Accuracy: 84.24%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [9/10], Loss: 154.4188, Accuracy: 84.39%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8245)\u001b[0m Epoch [10/10], Loss: 153.7864, Accuracy: 84.43%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 5]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.0422, -0.0951,  0.2390,  0.2632,  0.3767,  0.0839,  0.1473, -0.4110,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.0071, -0.2805, -0.0431, -0.0846, -0.0900,  0.4475,  0.2424, -0.2799,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.2834, -0.0548,  0.3706,  0.0182, -0.0511,  0.1169,  0.0841, -0.3413,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.3851]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.3559, -0.1838],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.5037, -1.0013],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.2932, -0.7972],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.1327, -0.4147],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.2736, -0.7907]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 276.2563, Accuracy: 62.73%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 1])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.0422, -0.0951,  0.2390,  0.2632,  0.3767,  0.0839,  0.1473, -0.4110,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.8607,  0.4325]], grad_fn=<SliceBackward0>)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: 0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.2527, -0.2546],\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.2989, -0.8339],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 220.2390, Accuracy: 72.74%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 189.3994, Accuracy: 78.56%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 172.6557, Accuracy: 81.45%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 162.3663, Accuracy: 83.08%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 156.1114, Accuracy: 83.93%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 152.3893, Accuracy: 84.39%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 150.0136, Accuracy: 84.75%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 148.9089, Accuracy: 84.89%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 148.3305, Accuracy: 84.97%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.0422, -0.0951,  0.2390,  0.2632,  0.3767,  0.0839,  0.1473, -0.4110,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.0071, -0.2805, -0.0431, -0.0846, -0.0900,  0.4475,  0.2424, -0.2799,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.2834, -0.0548,  0.3706,  0.0182, -0.0511,  0.1169,  0.0841, -0.3413,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.3851]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.1780, -0.3267],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.9630, -1.5364],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0842, -0.5659],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.3959, -0.8792],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.6061, -1.1142]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 270.8841, Accuracy: 63.18%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 218.6917, Accuracy: 73.21%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 189.1828, Accuracy: 78.90%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 173.0747, Accuracy: 81.57%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 163.2035, Accuracy: 83.05%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 157.2253, Accuracy: 83.95%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 153.5228, Accuracy: 84.37%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 151.2664, Accuracy: 84.65%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 150.0463, Accuracy: 84.77%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 149.6414, Accuracy: 84.87%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 6]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.1406, -0.1404,  0.4095,  0.2404,  0.5022,  0.1792,  0.0598, -0.1407,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.1329, -0.5086,  0.0822, -0.0017, -0.0318,  0.2926, -0.0590,  0.0486,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.1797, -0.0414,  0.4089,  0.0566, -0.1157, -0.1941,  0.1992, -0.1486,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.2732]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: 0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.1553, -0.6139],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.5305,  0.0572],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.9141,  0.3577],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.2049, -0.7329],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 1.1341, -1.6060]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.0316, -0.5291],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 262.4960, Accuracy: 66.57%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.1406, -0.1404,  0.4095,  0.2404,  0.5022,  0.1792,  0.0598, -0.1407,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.0730, -0.4497]], grad_fn=<SliceBackward0>)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.0546, -0.5850],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 206.1163, Accuracy: 76.00%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 175.6150, Accuracy: 81.20%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 159.0696, Accuracy: 83.68%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 149.1316, Accuracy: 85.14%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 143.1317, Accuracy: 85.93%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 139.5118, Accuracy: 86.45%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 137.2873, Accuracy: 86.68%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 135.7082, Accuracy: 86.88%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 135.5682, Accuracy: 86.91%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.1406, -0.1404,  0.4095,  0.2404,  0.5022,  0.1792,  0.0598, -0.1407,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.1329, -0.5086,  0.0822, -0.0017, -0.0318,  0.2926, -0.0590,  0.0486,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m          -0.1797, -0.0414,  0.4089,  0.0566, -0.1157, -0.1941,  0.1992, -0.1486,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.2732]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.3914, -0.9122],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.9737,  0.5040],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0022, -0.5257],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.5653,  0.0641],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0246, -0.5614]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 269.9277, Accuracy: 64.16%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 214.4662, Accuracy: 73.91%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 184.8468, Accuracy: 79.24%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 168.4345, Accuracy: 81.93%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 159.1205, Accuracy: 83.29%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 153.5927, Accuracy: 84.08%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 150.3210, Accuracy: 84.47%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 148.0642, Accuracy: 84.75%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 146.8933, Accuracy: 84.95%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 146.3674, Accuracy: 85.04%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 7]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 1])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.2195,  0.1463,  0.2872,  0.0784,  0.2279,  0.1724,  0.0021, -0.1956,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.1401, -0.7133, -0.1819,  0.0645, -0.1254,  0.3384, -0.0346,  0.1186,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.1265,  0.0778,  0.2736, -0.0249, -0.2181, -0.2839,  0.0421, -0.1307,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.4523]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.6773, -1.2092],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.9946, -1.6529],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0910, -0.5948],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0084, -0.5035],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.6469,  0.2414]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.5268,  0.0648],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 268.3125, Accuracy: 64.78%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.2195,  0.1463,  0.2872,  0.0784,  0.2279,  0.1724,  0.0021, -0.1956,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [-0.2256, -0.2792],\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: 0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.5323, -1.0514]], grad_fn=<SliceBackward0>)\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 208.9217, Accuracy: 75.19%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 178.1882, Accuracy: 80.57%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 162.4271, Accuracy: 82.95%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 153.4288, Accuracy: 84.25%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 147.8135, Accuracy: 84.93%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 144.5937, Accuracy: 85.33%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 142.6816, Accuracy: 85.56%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 141.6422, Accuracy: 85.70%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 141.2208, Accuracy: 85.80%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.2195,  0.1463,  0.2872,  0.0784,  0.2279,  0.1724,  0.0021, -0.1956,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.1401, -0.7133, -0.1819,  0.0645, -0.1254,  0.3384, -0.0346,  0.1186,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.1265,  0.0778,  0.2736, -0.0249, -0.2181, -0.2839,  0.0421, -0.1307,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.4523]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.0774, -0.5706],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.7785, -1.2756],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0726, -0.5249],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.0292, -0.5489],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.0468, -0.4846]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 270.2686, Accuracy: 64.32%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 208.5065, Accuracy: 75.12%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 177.8622, Accuracy: 80.42%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 162.0628, Accuracy: 82.85%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 152.8678, Accuracy: 84.18%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 147.3989, Accuracy: 84.89%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 144.1773, Accuracy: 85.32%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 141.9117, Accuracy: 85.64%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 141.0057, Accuracy: 85.74%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 140.8019, Accuracy: 85.73%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 8]\n","\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 0])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.2095,  0.2388,  0.2479, -0.0392,  0.1922,  0.3199, -0.0804, -0.1976,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0455, -0.4851, -0.0920, -0.1103,  0.0556,  0.2425, -0.1263, -0.0336,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0316,  0.3196,  0.1895, -0.0557, -0.2927, -0.0998, -0.1748, -0.2053,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.2644]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: 0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 1.2171, -1.7917],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.6897, -1.2601],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.4619, -0.9890],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.3648, -0.1391],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.1760, -0.6964]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Outputs sample logits: tensor([[-0.1720, -0.3381],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 271.3484, Accuracy: 65.71%\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0])\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.2095,  0.2388,  0.2479, -0.0392,  0.1922,  0.3199, -0.0804, -0.1976,\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m           0.2644]])\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8245)\u001b[0m         [ 0.5661, -1.0502]], grad_fn=<SliceBackward0>)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 206.0250, Accuracy: 76.00%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 172.8927, Accuracy: 81.45%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 155.5196, Accuracy: 84.05%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 146.2227, Accuracy: 85.32%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 140.7633, Accuracy: 86.00%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 137.2908, Accuracy: 86.54%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 135.1210, Accuracy: 86.82%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 134.2954, Accuracy: 86.87%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 134.1228, Accuracy: 86.91%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Labels bootstrap sample: tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] First decision node weights (Tree 0): tensor([[-0.2095,  0.2388,  0.2479, -0.0392,  0.1922,  0.3199, -0.0804, -0.1976,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0455, -0.4851, -0.0920, -0.1103,  0.0556,  0.2425, -0.1263, -0.0336,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.0316,  0.3196,  0.1895, -0.0557, -0.2927, -0.0998, -0.1748, -0.2053,\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m           0.2644]])\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Inputs mean: -0.0000, std: 0.9995\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m [DEBUG] Outputs sample logits: tensor([[ 0.8359, -1.3140],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.1890, -0.6524],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.8366, -1.2626],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [-0.6403,  0.1891],\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m         [ 0.2994, -0.8131]], grad_fn=<SliceBackward0>)\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [1/10], Loss: 264.7343, Accuracy: 66.04%\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [2/10], Loss: 204.8575, Accuracy: 75.81%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [3/10], Loss: 174.8710, Accuracy: 80.75%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [4/10], Loss: 159.5577, Accuracy: 83.18%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [5/10], Loss: 151.2720, Accuracy: 84.33%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [6/10], Loss: 145.6083, Accuracy: 85.11%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [7/10], Loss: 142.6464, Accuracy: 85.45%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [8/10], Loss: 140.8665, Accuracy: 85.65%\n","\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [9/10], Loss: 139.6387, Accuracy: 85.83%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=8244)\u001b[0m Epoch [10/10], Loss: 139.3594, Accuracy: 85.85%\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 1 clients (out of 3)\n","\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 1 results and 0 failures\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [SUMMARY]\n","\u001b[92mINFO \u001b[0m:      Run finished 8 round(s) in 3795.76s\n","\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n","\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.006508528797944904\n","\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.006493122259258059\n","\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.00649926406164511\n","\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.006374394078208103\n","\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.006506940635097143\n","\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.006453407898011347\n","\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.006484630441820971\n","\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.00655754051301689\n","\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n","\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.6188925081433225),\n","\u001b[92mINFO \u001b[0m:      \t              (2, 0.6188925081433225),\n","\u001b[92mINFO \u001b[0m:      \t              (3, 0.6188925081433225),\n","\u001b[92mINFO \u001b[0m:      \t              (4, 0.6449511400651465),\n","\u001b[92mINFO \u001b[0m:      \t              (5, 0.6188925081433225),\n","\u001b[92mINFO \u001b[0m:      \t              (6, 0.6449511400651465),\n","\u001b[92mINFO \u001b[0m:      \t              (7, 0.6449511400651465),\n","\u001b[92mINFO \u001b[0m:      \t              (8, 0.6384364820846905)]}\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[36m(pid=8245)\u001b[0m 2025-01-22 14:54:18.616671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(pid=8245)\u001b[0m 2025-01-22 14:54:18.705380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(pid=8245)\u001b[0m 2025-01-22 14:54:18.733876: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(pid=8245)\u001b[0m 2025-01-22 14:54:22.397170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["global configs\n","configs = {\n","    \"lr\": 0.01,\n","    \"local_epochs\": 10,\n","    \"NUM_CLIENTS\": 3,\n","    \"BATCH_SIZE\": 128,\n","    \"num_trees\": 50,\n","    \"input_size\": 57,\n","    \"depth\": 4,\n","    \"output_size\": 2,\n","    \"temperature\": 1.0,\n","    \"num_features\": 25,\n","    \"num_rounds\": 8,\n","    \"seed\": 42,\n","    \"test_size\": 0.2,\n","    \"patience\": 5,\n","    \"min_delta\": 1e-4,\n","}\n","\n","\n","\n","def client_fn(context):\n","    # Initialize client-specific model and data\n","    partition_id = context.node_config[\"partition-id\"]\n","    client_data = global_partitions[partition_id]  # Access preloaded partitions\n","\n","    trainloader = client_data[\"train\"]\n","    valloader = client_data[\"val\"]\n","    testloader = client_data[\"test\"]\n","\n","    #print(f\"[DEBUG] Client {partition_id}: Train size = {len(trainloader.dataset)}, \"\n","    #      f\"Val size = {len(valloader.dataset)}, Test size = {len(testloader.dataset)}\")\n","\n","\n","    model = SoftRandomForest(\n","        num_trees=configs[\"num_trees\"],\n","        input_size=configs[\"input_size\"],\n","        depth=configs[\"depth\"],\n","        output_size=configs[\"output_size\"],\n","        temperature=configs[\"temperature\"],\n","        num_features=configs[\"num_features\"])\n","\n","    # Return the FederatedClient wrapped as a Client instance\n","    return FederatedClient(model, trainloader, testloader).to_client()\n","\n","\n","\n","preload_datasets()\n","\n","# Configure resources for simulation\n","backend_config = {\"client_resources\": {\"num_cpus\": 1}}\n","\n","if torch.cuda.is_available():\n","    backend_config[\"client_resources\"][\"num_gpus\"] = 1.0\n","\n","# Run simulation\n","run_simulation(\n","    server_app=ServerApp(server_fn=server_fn),\n","    client_app=ClientApp(client_fn=client_fn),\n","    num_supernodes=configs[\"NUM_CLIENTS\"],\n","    backend_config=backend_config,\n",")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNtm4+scDBNMCoyOd6WxFtI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}